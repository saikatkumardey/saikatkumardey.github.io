<!doctype html><html dir=ltr lang=en data-theme class="html theme--light"><head><title>Predictive Model Performance Online and Offline Eval |
Saikat Kumar Dey</title><meta charset=utf-8><meta name=generator content="Hugo 0.115.2"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Saikat Kumar Dey"><meta name=description content="Machine Learning Engineer"><link rel=stylesheet href=/scss/main.min.1147aa5bacb4bce677a0e264073829caedb82fd18ea07a5f1d80521f539d1c45.css integrity="sha256-EUeqW6y0vOZ3oOJkBzgpyu24L9GOoHpfHYBSH1OdHEU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=https://saikatkumardey.com/post/predictive-model-performance-online-and-offline-eval/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc=" crossorigin=anonymous></script><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://saikatkumardey.com/images/site-feature-image.png"><meta name=twitter:title content="Predictive Model Performance Online and Offline Eval"><meta name=twitter:description content="Paper summary on how to reduce the discrepancy between offline and online evaluation of ML models"><meta property="og:title" content="Predictive Model Performance Online and Offline Eval"><meta property="og:description" content="Paper summary on how to reduce the discrepancy between offline and online evaluation of ML models"><meta property="og:type" content="article"><meta property="og:url" content="https://saikatkumardey.com/post/predictive-model-performance-online-and-offline-eval/"><meta property="og:image" content="https://saikatkumardey.com/images/site-feature-image.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-08-25T09:57:00+05:30"><meta property="article:modified_time" content="2021-08-25T09:57:00+05:30"><meta property="og:site_name" content="I'm Saikat Kumar Dey"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"Predictive Model Performance Online and Offline Eval","headline":"Predictive Model Performance Online and Offline Eval","alternativeHeadline":"","description":"
      
        Paper summary on how to reduce the discrepancy between offline and online evaluation of ML models


      


    ","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/saikatkumardey.com\/post\/predictive-model-performance-online-and-offline-eval\/"},"author":{"@type":"Person","name":"Saikat Kumar Dey"},"creator":{"@type":"Person","name":"Saikat Kumar Dey"},"accountablePerson":{"@type":"Person","name":"Saikat Kumar Dey"},"copyrightHolder":{"@type":"Person","name":"Saikat Kumar Dey"},"copyrightYear":"2021","dateCreated":"2021-08-25T09:57:00.00Z","datePublished":"2021-08-25T09:57:00.00Z","dateModified":"2021-08-25T09:57:00.00Z","publisher":{"@type":"Organization","name":"Saikat Kumar Dey","url":"https://saikatkumardey.com","logo":{"@type":"ImageObject","url":"https:\/\/saikatkumardey.com\/favicons\/favicon-32x32.png","width":"32","height":"32"}},"image":["https://saikatkumardey.com/images/site-feature-image.png"],"url":"https:\/\/saikatkumardey.com\/post\/predictive-model-performance-online-and-offline-eval\/","wordCount":"944","genre":["research","ml"],"keywords":[]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/dp.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>I'm Saikat Kumar Dey</a></div><div class=sidebar__introduction-description><p>Machine Learning Engineer</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://linkedin.com/in/saikatkumardey target=_blank rel="noopener me" aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/saikatkumardey/ target=_blank rel="noopener me" aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.instagram.com/saikatkumardey/ target=_blank rel="noopener me" aria-label=instagram title=instagram><i class="fab fa-instagram fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/saikatkrdey target=_blank rel="noopener me" aria-label=twitter title=twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:saikat@saikatkumardey.com target=_blank rel="noopener me" aria-label=Email title=Email><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Saikat Kumar Dey
2023</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=https://ai.saikatkumardey.com target=_blank rel="noopener noreferrer" title>AI</a></li><li class=nav__list-item><a href=/projects/ title>Projects</a></li><li class=nav__list-item><a href=/now/ title>Now</a></li><li class=nav__list-item><a href=/contact/ title>Contact</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Predictive Model Performance Online and Offline Eval</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>25/8/2021</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>5-minute read</span></li></ul><p>Evaluation is an important topic in every machine learning project. There are offline metrics that we compute on the historical data. It&rsquo;s supposed to provide us an indication of our model performance on real data. However, we often see a discrepancy in offline vs online performance.</p><p>In <a href=https://dl.acm.org/doi/abs/10.1145/2487575.2488215>Predictive model performance: Offline and online evaluations</a>, the authors investigate the offline/online model performance on advertisement data from Bing Search Engine.</p><h2 id=key-takeaways>Key takeaways</h2><ul><li>Evaluation metrics are important since it guides what the model optimizes on. Tuning on incorrect metrics might provide misleading results in offline settings that might surprise us in production.</li><li>AUC is a really good metric to determine model classification efficiency.</li><li>Offline evaluation using AUC doesn&rsquo;t correlate to the online evaluation via A/B tests.</li><li>The authors propose the usage of a simulation metric that simulates user behavior based on historical logs, which works better in the online evaluation.</li></ul><h2 id=details>Details</h2><p><strong>What is an offline evaluation?</strong></p><ul><li>In typical ML projects, we split our dataset into train/test sets.</li><li>Models are trained on the train set.</li><li>Evaluation is done on the test set.</li></ul><p><strong>What is an online evaluation?</strong></p><p>When our model is in production, we perform an A/B test.
Typically, it has 2 variants.</p><ul><li><em>control</em> group with our existing model</li><li><em>test</em> group with the new model.
Live traffic is split into the two groups & metrics like conversion rate, revenue per visitor, etc are measured. If the new model&rsquo;s performance is statistically significant, it&rsquo;s selected for launch.</li></ul><p><strong>The issue?</strong></p><p>Offline performance doesn&rsquo;t always correlate to online performance due to the dynamic nature of the latter.</p><h2 id=evaluation-metrics>Evaluation Metrics</h2><ul><li>The paper focuses on metrics used for click prediction problems that most search engines like Google, Bing, etc. face.</li><li>Click prediction problems estimates the CTRs of ads given a query.</li><li>This is treated as a binary classification problem.</li></ul><p>We&rsquo;ll review some important evaluation metrics for the use case.</p><h3 id=auc-area-under-curve>AUC (Area under curve)</h3><ul><li>Let&rsquo;s say that we have a binary classifier that predicts a probability <em>p</em> for an event to occur. Then, <em>1-p</em> is the probability that the event doesn&rsquo;t occur. We need a threshold to determine the class membership. AUC provides a single score that tells us how good a model is across all possible ranges of thresholds.</li><li>AUC is computed from a ROC (Receiver Operating Characteristics) curve.</li><li>ROC curve = a graphical representation of TPR (true positive rate) as a function of FPR (false positive rate) of a binary classifier across different thresholds.</li></ul><h3 id=rig-relative-information-gain>RIG (Relative Information Gain)</h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>RIG = 1 - log_loss/entropy(y)
</span></span><span class=line><span class=cl>where,
</span></span><span class=line><span class=cl>log_loss     = - [ c*log(p) + (1-c)*log(1-p) ]
</span></span><span class=line><span class=cl>entropy(y) = - [ y*logy + (1-y)*log(1-y) ]
</span></span><span class=line><span class=cl>c = observed click
</span></span><span class=line><span class=cl>p = probability of a click
</span></span><span class=line><span class=cl>y = CTR
</span></span></code></pre></div><p>Higher is better.</p><h3 id=prediction-error-pe>Prediction Error (PE)</h3><p><code>PE = avg(p)/y - 1</code></p><ul><li>PE = 0 when average(p) exactly matches the click-through rate.</li><li>It could also be 0 if there&rsquo;s a mix of over-estimation/under-estimation of the CTR as long the average is closer to CTR.</li><li>It&rsquo;s not a reliable metric.</li></ul><h3 id=simulation-metric>Simulation Metric</h3><p>This part is really important. It teaches us a way to simulate different model performances offline without having to run expensive A/B tests.</p><ul><li>A/B tests run with a fixed set of model parameters.<ul><li>It could be expensive to run multiple experiments with different model parameters.</li><li>It could also ruin the user experience, make losses if the new model underperforms</li></ul></li><li>The paper proposes a simulation of the user behavior offline aka auction simulation.</li><li>Auction simulation reruns ad auctions offline for a given query and selects a set of ads based on the new model prediction scores.</li><li>user clicks are estimated in the following way:<ul><li>if (user, ad) pair is found in the logs<ul><li>if it&rsquo;s in the same position in history as in the simulation, use the historic CTR directly as the expected CTR</li><li>if it&rsquo;s not in the same position, the expected CTR is calibrated based on the position.</li></ul></li><li>if (user, ad) pair is not found, average CTR is used as the expected CTR.</li></ul></li></ul><h2 id=issues>Issues</h2><h3 id=auc>AUC</h3><ul><li>ignores predicted probability values. It&rsquo;s insensitive to the ranking based on the probability score. It&rsquo;s possible to have different rankings with similar AUC scores.</li><li>summarizes the test performance over the entire range of the ROC space, even where one would rarely operate on. Higher ROC doesn&rsquo;t mean a better ranking.</li><li>It weights false-positive and false negatives equally. In real life, the cost of not showing a relevant ad (false negatives) is way more than showing a sub-optimal ad (false positive).</li><li>highly dependent on the underlying data distribution.</li></ul><h3 id=rig>RIG</h3><ul><li>Highly sensitive to underlying data distribution.</li><li>We can&rsquo;t judge a model by just using RIG alone.</li><li>We could compare the relative performance of different models trained/tested on the same data.</li></ul><h2 id=offline-vs-online-discrepancy>Offline vs Online discrepancy</h2><p>The authors compare 2 models</p><ul><li>model 1 (baseline): tuned on offline metrics like AUC & RIG</li><li>model 2 (test): tuned on the simulation metric</li></ul><p>The finding: model performs well on offline metrics but has a significant dip on online metrics.</p><p><strong>Why do we see this?</strong></p><p><img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1629743092351/g_2-BgJ8G.png alt="Screenshot 2021-08-23 at 11.54.47 PM.png"></p><ul><li>Tuning a model on offline metrics like AUC/RIG over-estimates the probability scores at the lower end of the score range.</li><li>Over-estimation of the probability score at the higher end of the score range doesn&rsquo;t matter much since they&rsquo;ll be selected by either model.</li><li>Over-estimation at the lower end of the score range is bad since irrelevant ads are more likely to be shown in that case.</li><li>Offline metrics like AUC/RIG provide an overall score based on the entire range of probability scores - they&rsquo;re not able to capture the intended effect.</li><li>Tuning a model based on the simulation metric correlates better with online performance tests via A/B tests.</li></ul><h2 id=references>References</h2><p><a href=https://dl.acm.org/doi/abs/10.1145/2487575.2488215>Predictive Model Performance: Offline and Online Evaluations</a></p></div><div class=post__footer><span><a class=category href=/categories/research/>research</a><a class=category href=/categories/ml/>ml</a></span></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Saikat Kumar Dey
2023</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></body></html>