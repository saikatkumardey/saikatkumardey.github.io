<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Predictive Model Performance Online and Offline Eval - Saikat Kumar Dey</title><meta name=description content="Paper summary on how to reduce the discrepancy between offline and online evaluation of ML models"><meta name=author content="Saikat Kumar Dey"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Saikat Kumar Dey","url":"https:\/\/saikatkumardey.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/saikatkumardey.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/saikatkumardey.com","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/saikatkumardey.com\/post\/predictive-model-performance-online-and-offline-eval\/","name":"Predictive model performance online and offline eval"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Saikat Kumar Dey"},"headline":"Predictive Model Performance Online and Offline Eval","description":"Paper summary on how to reduce the discrepancy between offline and online evaluation of ML models","inLanguage":"en","wordCount":944,"datePublished":"2021-08-25T09:57:00","dateModified":"2021-08-25T09:57:00","image":"https:\/\/saikatkumardey.com","keywords":[""],"mainEntityOfPage":"https:\/\/saikatkumardey.com\/post\/predictive-model-performance-online-and-offline-eval\/","publisher":{"@type":"Organization","name":"https:\/\/saikatkumardey.com","logo":{"@type":"ImageObject","url":"https:\/\/saikatkumardey.com","height":60,"width":60}}}</script><meta property="og:url" content="https://saikatkumardey.com/post/predictive-model-performance-online-and-offline-eval/"><meta property="og:type" content="website"><meta property="og:site_name" content="Saikat Kumar Dey"><link rel=apple-touch-icon sizes=180x180 href=https://saikatkumardey.com/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://saikatkumardey.com/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://saikatkumardey.com/favicon/favicon-16x16.png><meta name=generator content="Hugo 0.115.4"><link rel=alternate href=https://saikatkumardey.com/index.xml type=application/rss+xml title="Saikat Kumar Dey"><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link rel=stylesheet href=https://saikatkumardey.com/css/main.css><link disabled id=dark-mode-theme rel=stylesheet href=https://saikatkumardey.com/css/dark.css><link rel=stylesheet href=https://saikatkumardey.com/css/highlight.min.css><link rel=stylesheet href=https://saikatkumardey.com/css/codeblock.css></head><body><div class="container fixed-top"><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-10 col-xl-10"><nav class="navbar navbar-expand-lg navbar-light fixed-top p-0"><div class=container><a class="navbar-brand fw-bold" href=https://saikatkumardey.com>Saikat Kumar Dey</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-end" id=navbarNav><ul class="navbar-nav mb-2 mb-lg-0"><li class=nav-item><a class=nav-link title=Home href=/>Home</a></li><li class=nav-item><a class=nav-link title=Projects href=/projects/>Projects</a></li><li class=nav-item><a class=nav-link title=Now href=/now/>Now</a></li><li class="nav-item nav-link"><a id=dark-mode-toggle class="bi bi-sun"></a></li></ul></div></div></nav></div></div></div><header class=header-section><div class="intro-header no-img mt-10"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-8 col-xl-8"><div class="col-sm-12 col-md-12 col-lg-12 col-xl-12"><div class=post-heading><h1 class="fw-semibold display-5 lh-1 mb-3">Predictive Model Performance Online and Offline Eval</h1><span class=post-meta>&nbsp;August 25, 2021</span></div></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><div class="card-image card-image-blog p-0"></div></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><article role=main class=blog-post><p>Evaluation is an important topic in every machine learning project. There are offline metrics that we compute on the historical data. It&rsquo;s supposed to provide us an indication of our model performance on real data. However, we often see a discrepancy in offline vs online performance.</p><p>In <a href=https://dl.acm.org/doi/abs/10.1145/2487575.2488215>Predictive model performance: Offline and online evaluations</a>, the authors investigate the offline/online model performance on advertisement data from Bing Search Engine.</p><h2 id=key-takeaways>Key takeaways</h2><ul><li>Evaluation metrics are important since it guides what the model optimizes on. Tuning on incorrect metrics might provide misleading results in offline settings that might surprise us in production.</li><li>AUC is a really good metric to determine model classification efficiency.</li><li>Offline evaluation using AUC doesn&rsquo;t correlate to the online evaluation via A/B tests.</li><li>The authors propose the usage of a simulation metric that simulates user behavior based on historical logs, which works better in the online evaluation.</li></ul><h2 id=details>Details</h2><p><strong>What is an offline evaluation?</strong></p><ul><li>In typical ML projects, we split our dataset into train/test sets.</li><li>Models are trained on the train set.</li><li>Evaluation is done on the test set.</li></ul><p><strong>What is an online evaluation?</strong></p><p>When our model is in production, we perform an A/B test.
Typically, it has 2 variants.</p><ul><li><em>control</em> group with our existing model</li><li><em>test</em> group with the new model.
Live traffic is split into the two groups & metrics like conversion rate, revenue per visitor, etc are measured. If the new model&rsquo;s performance is statistically significant, it&rsquo;s selected for launch.</li></ul><p><strong>The issue?</strong></p><p>Offline performance doesn&rsquo;t always correlate to online performance due to the dynamic nature of the latter.</p><h2 id=evaluation-metrics>Evaluation Metrics</h2><ul><li>The paper focuses on metrics used for click prediction problems that most search engines like Google, Bing, etc. face.</li><li>Click prediction problems estimates the CTRs of ads given a query.</li><li>This is treated as a binary classification problem.</li></ul><p>We&rsquo;ll review some important evaluation metrics for the use case.</p><h3 id=auc-area-under-curve>AUC (Area under curve)</h3><ul><li>Let&rsquo;s say that we have a binary classifier that predicts a probability <em>p</em> for an event to occur. Then, <em>1-p</em> is the probability that the event doesn&rsquo;t occur. We need a threshold to determine the class membership. AUC provides a single score that tells us how good a model is across all possible ranges of thresholds.</li><li>AUC is computed from a ROC (Receiver Operating Characteristics) curve.</li><li>ROC curve = a graphical representation of TPR (true positive rate) as a function of FPR (false positive rate) of a binary classifier across different thresholds.</li></ul><h3 id=rig-relative-information-gain>RIG (Relative Information Gain)</h3><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>RIG = 1 - log_loss/entropy(y)
</span></span><span style=display:flex><span>where,
</span></span><span style=display:flex><span>log_loss     = - [ c*log(p) + (1-c)*log(1-p) ]
</span></span><span style=display:flex><span>entropy(y) = - [ y*logy + (1-y)*log(1-y) ]
</span></span><span style=display:flex><span>c = observed click
</span></span><span style=display:flex><span>p = probability of a click
</span></span><span style=display:flex><span>y = CTR
</span></span></code></pre></div><p>Higher is better.</p><h3 id=prediction-error-pe>Prediction Error (PE)</h3><p><code>PE = avg(p)/y - 1</code></p><ul><li>PE = 0 when average(p) exactly matches the click-through rate.</li><li>It could also be 0 if there&rsquo;s a mix of over-estimation/under-estimation of the CTR as long the average is closer to CTR.</li><li>It&rsquo;s not a reliable metric.</li></ul><h3 id=simulation-metric>Simulation Metric</h3><p>This part is really important. It teaches us a way to simulate different model performances offline without having to run expensive A/B tests.</p><ul><li>A/B tests run with a fixed set of model parameters.<ul><li>It could be expensive to run multiple experiments with different model parameters.</li><li>It could also ruin the user experience, make losses if the new model underperforms</li></ul></li><li>The paper proposes a simulation of the user behavior offline aka auction simulation.</li><li>Auction simulation reruns ad auctions offline for a given query and selects a set of ads based on the new model prediction scores.</li><li>user clicks are estimated in the following way:<ul><li>if (user, ad) pair is found in the logs<ul><li>if it&rsquo;s in the same position in history as in the simulation, use the historic CTR directly as the expected CTR</li><li>if it&rsquo;s not in the same position, the expected CTR is calibrated based on the position.</li></ul></li><li>if (user, ad) pair is not found, average CTR is used as the expected CTR.</li></ul></li></ul><h2 id=issues>Issues</h2><h3 id=auc>AUC</h3><ul><li>ignores predicted probability values. It&rsquo;s insensitive to the ranking based on the probability score. It&rsquo;s possible to have different rankings with similar AUC scores.</li><li>summarizes the test performance over the entire range of the ROC space, even where one would rarely operate on. Higher ROC doesn&rsquo;t mean a better ranking.</li><li>It weights false-positive and false negatives equally. In real life, the cost of not showing a relevant ad (false negatives) is way more than showing a sub-optimal ad (false positive).</li><li>highly dependent on the underlying data distribution.</li></ul><h3 id=rig>RIG</h3><ul><li>Highly sensitive to underlying data distribution.</li><li>We can&rsquo;t judge a model by just using RIG alone.</li><li>We could compare the relative performance of different models trained/tested on the same data.</li></ul><h2 id=offline-vs-online-discrepancy>Offline vs Online discrepancy</h2><p>The authors compare 2 models</p><ul><li>model 1 (baseline): tuned on offline metrics like AUC & RIG</li><li>model 2 (test): tuned on the simulation metric</li></ul><p>The finding: model performs well on offline metrics but has a significant dip on online metrics.</p><p><strong>Why do we see this?</strong></p><p><img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1629743092351/g_2-BgJ8G.png alt="Screenshot 2021-08-23 at 11.54.47 PM.png"></p><ul><li>Tuning a model on offline metrics like AUC/RIG over-estimates the probability scores at the lower end of the score range.</li><li>Over-estimation of the probability score at the higher end of the score range doesn&rsquo;t matter much since they&rsquo;ll be selected by either model.</li><li>Over-estimation at the lower end of the score range is bad since irrelevant ads are more likely to be shown in that case.</li><li>Offline metrics like AUC/RIG provide an overall score based on the entire range of probability scores - they&rsquo;re not able to capture the intended effect.</li><li>Tuning a model based on the simulation metric correlates better with online performance tests via A/B tests.</li></ul><h2 id=references>References</h2><p><a href=https://dl.acm.org/doi/abs/10.1145/2487575.2488215>Predictive Model Performance: Offline and Online Evaluations</a></p></article></div></div><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><hr></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-2"></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><div><p class="list-inline footer-links">Use the share button below if you liked it.</p></div><ul class=share><li><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fsaikatkumardey.com%2fpost%2fpredictive-model-performance-online-and-offline-eval%2f" target=_blank title="Share on Facebook"><i class="bi bi-facebook facebook-color"></i></a></li><li><a href="//twitter.com/share?url=https%3a%2f%2fsaikatkumardey.com%2fpost%2fpredictive-model-performance-online-and-offline-eval%2f&amp;text=Predictive%20Model%20Performance%20Online%20and%20Offline%20Eval&amp;via=map%5bemail%3asample%40gmail.com%20facebook%3ausername%20github%3asaikatkumardey%20linkedin%3asaikatkumardey%20name%3aSaikat%20Kumar%20Dey%20twitter%3asaikatkrdey%20website%3ahttps%3a%2f%2fsaikatkumardey.com%2f%20youtube%3a%5d" target=_blank title="Share on Twitter"><i class="bi bi-twitter twitter-color"></i></a></li><li><a href="//reddit.com/submit?url=https%3a%2f%2fsaikatkumardey.com%2fpost%2fpredictive-model-performance-online-and-offline-eval%2f&amp;title=Predictive%20Model%20Performance%20Online%20and%20Offline%20Eval" target=_blank title="Share on Reddit"><i class="bi bi-reddit reddit-color"></i></a></li><li><a href="whatsapp://send?text=https%3a%2f%2fsaikatkumardey.com%2fpost%2fpredictive-model-performance-online-and-offline-eval%2f&amp;description=Predictive%20Model%20Performance%20Online%20and%20Offline%20Eval" target=_blank rel=noopener title="Share on WhatsApp"><i class="bi bi-whatsapp whatsapp-color"></i></a></li></ul></div></div></section></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><ul class="list-group list-group-horizontal" style=flex-direction:row><li class="list-group-item ms-auto b-0"><a type=button class="btn btn-dark" role=button href=https://saikatkumardey.com/post/deep-nn-for-youtube-recommendations/ data-toggle=tooltip data-placement=top title="Deep Neural Networks for YouTube Recommendations">Next Post
&rarr;</a></li></ul></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"></div></div></div><div><div class=container><div class=row></div></div></div></div></div><footer><div class=container><div class=row><div class=col-md-12><ul class="list-inline list-group list-group-horizontal text-center footer-links d-flex justify-content-center flex-row"><li><a href=mailto:sample@gmail.com title="Email me" target=_blank><span class=mx-2><i class="bi bi-envelope"></i></span></a></li><li><a href=https://www.facebook.com/username title=Facebook target=_blank><span class=mx-2><i class="bi bi-facebook"></i></span></a></li><li><a href=https://github.com/saikatkumardey title=GitHub target=_blank><span class=mx-2><i class="bi bi-github"></i></span></a></li><li><a href=https://twitter.com/saikatkrdey title=Twitter target=_blank><span class=mx-2><i class="bi bi-twitter"></i></span></a></li><li><a href=https://linkedin.com/in/saikatkumardey title=LinkedIn target=_blank><span class=mx-2><i class="bi bi-linkedin"></i></span></a></li><li><a href=https://www.youtube.com/ title=Youtube target=_blank><span class=mx-2><i class="bi bi-youtube"></i></span></a></li></ul></div></div><div class=row><div class=col-md-12><p class="credits copyright text-muted"><a href=https://saikatkumardey.com/>Saikat Kumar Dey</a>
&nbsp;&bull;&nbsp;&copy;
2023
&nbsp;&bull;&nbsp;
<a href=https://saikatkumardey.com>Saikat Kumar Dey</a></p><p class="credits theme-by text-muted">Powered by <a href=https://gohugo.io>Hugo</a> & <a href=https://github.com/binokochumolvarghese/lightbi-hugo>Lightbi.</a>&nbsp; Made with ❤ by <a href=https://binovarghese.com>Bino</a></p></div></div></div></footer><script src=https://code.jquery.com/jquery-3.7.0.slim.min.js integrity="sha256-tG5mcZUtJsZvyKAxYLVXrmjKBVLd6VpVccqz/r4ypFE=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.min.js integrity=sha384-Y4oOpwW3duJdCWv5ly8SCFYWqFDsfob/3GkgExXKV4idmbt98QcxXYs9UoXAB7BZ crossorigin=anonymous></script>
<script src=https://saikatkumardey.com/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script src=https://saikatkumardey.com/js/dark-mode.js></script></body></html>