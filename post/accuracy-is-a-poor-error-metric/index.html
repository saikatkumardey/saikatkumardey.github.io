<!doctype html><html dir=ltr lang=en data-theme class="html theme--light"><head><title>Accuracy Is a Poor evaluation Metric |
Saikat Kumar Dey</title><meta charset=utf-8><meta name=generator content="Hugo 0.111.3"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="Saikat Kumar Dey"><meta name=description content="Machine Learning Engineer"><link rel=stylesheet href=/scss/main.min.1147aa5bacb4bce677a0e264073829caedb82fd18ea07a5f1d80521f539d1c45.css integrity="sha256-EUeqW6y0vOZ3oOJkBzgpyu24L9GOoHpfHYBSH1OdHEU=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.7d272de35b410fb165377550cdf9c4d3a80fbbcc961e111914e4d5c0eaf5729f.css integrity="sha256-fSct41tBD7FlN3VQzfnE06gPu8yWHhEZFOTVwOr1cp8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.55d8333481b07a08e07cf6f37319753a2b47e99f4c395394c5747b48b495aa9b.css integrity="sha256-VdgzNIGwegjgfPbzcxl1OitH6Z9MOVOUxXR7SLSVqps=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.a7448d02590b43449364b6b5922ed9af5410abb4de4238412a830316dedb850b.css integrity="sha256-p0SNAlkLQ0STZLa1ki7Zr1QQq7TeQjhBKoMDFt7bhQs=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.9ed75a5d670c953fe4df935937674b4646f92674367e9e66eb995bb04e821647.css integrity="sha256-ntdaXWcMlT/k35NZN2dLRkb5JnQ2fp5m65lbsE6CFkc=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=https://saikatkumardey.com/post/accuracy-is-a-poor-error-metric/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/anatole-theme-switcher.min.d6d329d93844b162e8bed1e915619625ca91687952177552b9b3e211014a2957.js integrity="sha256-1tMp2ThEsWLovtHpFWGWJcqRaHlSF3VSubPiEQFKKVc=" crossorigin=anonymous></script><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://saikatkumardey.com/images/site-feature-image.png"><meta name=twitter:title content="Accuracy Is a Poor evaluation Metric"><meta name=twitter:description content="Issues with using accuracy as an evaluation metric and what you should use instead"><meta property="og:title" content="Accuracy Is a Poor evaluation Metric"><meta property="og:description" content="Issues with using accuracy as an evaluation metric and what you should use instead"><meta property="og:type" content="article"><meta property="og:url" content="https://saikatkumardey.com/post/accuracy-is-a-poor-error-metric/"><meta property="og:image" content="https://saikatkumardey.com/images/site-feature-image.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-06-07T10:25:15+05:30"><meta property="article:modified_time" content="2022-06-07T10:25:15+05:30"><meta property="og:site_name" content="Saikat Kumar Dey"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"Accuracy Is a Poor evaluation Metric","headline":"Accuracy Is a Poor evaluation Metric","alternativeHeadline":"","description":"
      
        Issues with using accuracy as an evaluation metric and what you should use instead


      


    ","inLanguage":"en","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/saikatkumardey.com\/post\/accuracy-is-a-poor-error-metric\/"},"author":{"@type":"Person","name":"Saikat Kumar Dey"},"creator":{"@type":"Person","name":"Saikat Kumar Dey"},"accountablePerson":{"@type":"Person","name":"Saikat Kumar Dey"},"copyrightHolder":{"@type":"Person","name":"Saikat Kumar Dey"},"copyrightYear":"2022","dateCreated":"2022-06-07T10:25:15.00Z","datePublished":"2022-06-07T10:25:15.00Z","dateModified":"2022-06-07T10:25:15.00Z","publisher":{"@type":"Organization","name":"Saikat Kumar Dey","url":"https://saikatkumardey.com","logo":{"@type":"ImageObject","url":"https:\/\/saikatkumardey.com\/favicons\/favicon-32x32.png","width":"32","height":"32"}},"image":["https://saikatkumardey.com/images/site-feature-image.png"],"url":"https:\/\/saikatkumardey.com\/post\/accuracy-is-a-poor-error-metric\/","wordCount":"546","genre":["ml"],"keywords":[]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/dp.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>Saikat Kumar Dey</a></div><div class=sidebar__introduction-description><p>Machine Learning Engineer</p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://linkedin.com/in/saikatkumardey target=_blank rel="noopener me" aria-label=Linkedin title=Linkedin><i class="fab fa-linkedin fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://github.com/saikatkumardey/ target=_blank rel="noopener me" aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://www.instagram.com/saikatkumardey/ target=_blank rel="noopener me" aria-label=instagram title=instagram><i class="fab fa-instagram fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=https://twitter.com/saikatkrdey target=_blank rel="noopener me" aria-label=twitter title=twitter><i class="fab fa-twitter fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:saikat@saikatkumardey.com target=_blank rel="noopener me" aria-label=Email title=Email><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
Saikat Kumar Dey
2023</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>Home</a></li><li class=nav__list-item><a href=/post/ title>Posts</a></li><li class=nav__list-item><a href=https://ai.saikatkumardey.com target=_blank rel="noopener noreferrer" title>AI</a></li><li class=nav__list-item><a href=/projects/ title>Projects</a></li><li class=nav__list-item><a href=/now/ title>Now</a></li><li class=nav__list-item><a href=/contact/ title>Contact</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>Accuracy Is a Poor Evaluation Metric</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>7/6/2022</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>3-minute read</span></li></ul><p>For classification problems, something like Cross-entropy is a good metric for minimizing your model&rsquo;s loss.
However, we need something easier to convey to the stakeholders.
Accuracy is a very easy way to show our model performances. The caveat? Accuracy would be misleading for imbalanced classes.</p><p>Here&rsquo;s why.</p><p>Let&rsquo;s say that you&rsquo;ve built a model for detecting cancer.
Here&rsquo;s how the confusion matrix would look like for a dataset on cancer cases.</p><table><thead><tr><th></th><th>Predicted Cancer</th><th>Predicted cancer-free</th></tr></thead><tbody><tr><td>Actual cancer cases</td><td>10 (TP)</td><td>5 (FN)</td></tr><tr><td>Actual cancer-free cases</td><td>150 (FP)</td><td>800 (TN)</td></tr></tbody></table><p>The dataset has 950 cancer-free patients and 15 patients with cancer.
The accuracy of the model = fraction of correct predictions = (10 + 800) / (10 + 5 + 150 + 800) = 0.84.</p><p>Well, the cancer cases are quite rare, so it barely has any effect on the accuracy.</p><p>If the model had predicted every case as cancer-free, the confusion matrix would look like the following:</p><table><thead><tr><th></th><th>Predicted Cancer</th><th>Predicted cancer-free</th></tr></thead><tbody><tr><td>Actual cancer cases</td><td>0 (TP)</td><td>15 (FN)</td></tr><tr><td>Actual cancer-free cases</td><td>0 (FP)</td><td>950 (TN)</td></tr></tbody></table><p>Accuracy = 950/(950 + 15) = 0.984%.</p><p>That is not what we want to report to our stakeholders.</p><p>What are our options?</p><p>In such cases with class imbalance, we usually look at <em>precision</em> and <em>recall</em>.</p><p><strong>Precision</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>precision = TP/(TP + FP)
</span></span></code></pre></div><p>Precision is <em>out of all the cancer diagnosis made by the model, how many of them actually have cancer</em>. In the first case, model predicted 165 cases as having cancer but only 15 of them actually had cancer. So, the precision is 15/165 which is quite low!</p><p><strong>Recall</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>recall = TP/(TP+FN)
</span></span></code></pre></div><p>Recall is <em>out of all the actual cancer cases, how many could the model detect?</em>
In the first case, model detected 15 out of 20 cancer cases. So, the recall is 15/20 = 0.75. That&rsquo;s not bad!</p><p>Our objective is to detect as many cancer cases as we can (TP) while minimizing the false diagnosis of cancer (FP). In other words, we want to have high recall with high precision.</p><p>All of these metrics rely on the probability threshold chosen to classify each sample as having cancer or not. If prediction probability > threshold, predict cancer.</p><p>For example, if you choose 0.9 as the threshold, you might only classify cases where the model is highly confident ie, high precision. However, you might miss out on many cases at that threshold ie, low recall. Instead, if you keep 0.1 as the threshold, you might capture all the cancer cases but you&rsquo;d be scaring a lot of other cancer-free patients with misdiagnosis as well.</p><p>By varying the probability threshold, you could check the trade-off between precision & recall, also called the precision-recall curve.</p><p>Sometimes, precision & recall are combined together into one metric, called F1 score.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>F1 = 2 / (1/precision + 1/recall)
</span></span></code></pre></div><p>There&rsquo;s another variant of the precision-recall curve which is agnostic to the probability threshold selected. It&rsquo;s called the ROC curve (Receiver Operating Characteristics). The area under the curve (AUC) is demonstrative of the overall model performance. AUC is useful to know how well the model is in classifying both the classes.</p><p><strong>Conclusion</strong></p><ul><li>Do not use accuracy metric when there&rsquo;s a class imbalance.</li><li>Use F1 or ROC-AUC instead.</li></ul><hr><p><strong>Reference</strong></p><ol><li><p><a href=https://www.oreilly.com/library/view/practical-machine-learning/9781098102357/>Practical Machine Learning for Computer Vision</a></p></li><li><p><a href=https://en.wikipedia.org/wiki/Precision_and_recall>Precision Recall</a></p></li><li><p><a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic>ROC Curve</a></p></li></ol></div><div class=post__footer><span><a class=category href=/categories/ml/>ml</a></span></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
Saikat Kumar Dey
2023</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></body></html>