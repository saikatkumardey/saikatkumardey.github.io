<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Deep Neural Networks for YouTube Recommendations - Saikat Kumar Dey</title><meta name=description content="Paper summary on how to generate relevant YouTube recommendations"><meta name=author content="Saikat Kumar Dey"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Saikat Kumar Dey","url":"https:\/\/saikatkumardey.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"https:\/\/saikatkumardey.com"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https:\/\/saikatkumardey.com","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"https:\/\/saikatkumardey.com\/post\/deep-nn-for-youtube-recommendations\/","name":"Deep neural networks for you tube recommendations"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"Saikat Kumar Dey"},"headline":"Deep Neural Networks for YouTube Recommendations","description":"Paper summary on how to generate relevant YouTube recommendations","inLanguage":"en","wordCount":857,"datePublished":"2021-08-29T09:59:03","dateModified":"2021-08-29T09:59:03","image":"https:\/\/saikatkumardey.com","keywords":[""],"mainEntityOfPage":"https:\/\/saikatkumardey.com\/post\/deep-nn-for-youtube-recommendations\/","publisher":{"@type":"Organization","name":"https:\/\/saikatkumardey.com","logo":{"@type":"ImageObject","url":"https:\/\/saikatkumardey.com","height":60,"width":60}}}</script><meta property="og:url" content="https://saikatkumardey.com/post/deep-nn-for-youtube-recommendations/"><meta property="og:type" content="website"><meta property="og:site_name" content="Saikat Kumar Dey"><link rel=apple-touch-icon sizes=180x180 href=https://saikatkumardey.com/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://saikatkumardey.com/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://saikatkumardey.com/favicon/favicon-16x16.png><meta name=generator content="Hugo 0.115.4"><link rel=alternate href=https://saikatkumardey.com/index.xml type=application/rss+xml title="Saikat Kumar Dey"><link href=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/css/bootstrap.min.css rel=stylesheet integrity=sha384-KK94CHFLLe+nY2dmCWGMq91rCGa5gtU4mk92HdvYe+M/SXH301p5ILy+dN9+nJOZ crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.5.0/font/bootstrap-icons.css><link rel=stylesheet href=https://saikatkumardey.com/css/main.css><link disabled id=dark-mode-theme rel=stylesheet href=https://saikatkumardey.com/css/dark.css><link rel=stylesheet href=https://saikatkumardey.com/css/highlight.min.css><link rel=stylesheet href=https://saikatkumardey.com/css/codeblock.css></head><body><div class="container fixed-top"><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-10 col-xl-10"><nav class="navbar navbar-expand-lg navbar-light fixed-top p-0"><div class=container><a class="navbar-brand fw-bold" href=https://saikatkumardey.com>Saikat Kumar Dey</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-end" id=navbarNav><ul class="navbar-nav mb-2 mb-lg-0"><li class=nav-item><a class=nav-link title=Home href=/>Home</a></li><li class=nav-item><a class=nav-link title=Projects href=/projects/>Projects</a></li><li class=nav-item><a class=nav-link title=Now href=/now/>Now</a></li><li class="nav-item nav-link"><a id=dark-mode-toggle class="bi bi-sun"></a></li></ul></div></div></nav></div></div></div><header class=header-section><div class="intro-header no-img mt-10"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-8 col-xl-8"><div class="col-sm-12 col-md-12 col-lg-12 col-xl-12"><div class=post-heading><h1 class="fw-semibold display-5 lh-1 mb-3">Deep Neural Networks for YouTube Recommendations</h1><span class=post-meta>&nbsp;August 29, 2021</span></div></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><div class="card-image card-image-blog p-0"></div></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><article role=main class=blog-post><p><img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1629830470549/vXmBYRQ6P.png alt="Screenshot 2021-08-25 at 12.11.06 AM.png"></p><p>YouTube has 100m+ daily active users who consume more than a billion hours&rsquo; worth of content every day. 100s of hours of videos are uploaded every second. At that scale, recommending personalized videos is a colossal task.</p><p>I&rsquo;ve always wondered how YouTube is always able to come up with relevant recommendations that kept me hooked! I found a very interesting paper on <a href=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf>Deep Neural networks for YouTube Recommendations</a>. In this post, I will summarise the key ideas.</p><h2 id=the-problem>The Problem</h2><p>To able to come up with relevant & personalized recommendations for every user is a problem because of:</p><ul><li><strong>scale</strong>: billions of users, billions of videos.</li><li><strong>freshness</strong>: massive volume of videos are uploaded every day. It&rsquo;s an explore-exploit trade-off between popular vs new content.</li><li><strong>noise</strong>: only sparse implicit user feedback is available for modeling.</li></ul><p>In this paper, the authors demonstrate the usage of deep learning techniques for improving recommendations as opposed to matrix-factorization techniques used earlier.</p><h2 id=key-ideas>Key Ideas</h2><ul><li><p>The problem of recommendations at scale is divided into 2 subproblems:</p><ol><li><strong>Candidate Generation</strong> - selects a small subset from the overall corpus which might be relevant to the user.</li><li><strong>Ranking</strong> - ranks the candidate videos based on their relative importance.</li></ol></li><li><p>For Candidate Generation, the objective is to predict the next video watch. User search/watch history, demographics, etc are used by a simple feed-forward network as embeddings which are jointly learned during the training.</p></li><li><p>For Ranking, the objective is to model an expected watch time. A score is assigned based on the expected watch time and videos are sorted accordingly.</p></li><li><p>Similar neural network architecture is used for both procedures.</p></li><li><p>Offline metrics like precision, recall, ranking loss, etc. are used during development. A/B test is used to determine the final effectiveness of the model. We&rsquo;ve already explored the <a href=https://saikatkumardey.com/predictive-model-performance-offline-and-online-evaluations>discrepancies between offline vs online evaluation</a> in a different post.</p></li></ul><h2 id=model-architecture>Model Architecture</h2><h3 id=candidate-generation>Candidate generation</h3><p><img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1630224116536/RukzfmlR1.png alt="Screenshot 2021-08-29 at 1.31.51 PM.png"></p><ul><li><p>** Problem Formulation:** Recommendation is formulated as an <em>extreme multi-class classification</em>
P(w_t = i | U,C) = softmax(v_i . u)
where,
w_t = video v_i watched at time t
U = user
C = context
v_i = dense video embeddings
u = dense user embeddings</p><ul><li>The task of the deep neural network is to learn the embeddings <em>u</em> as a function of user history and context.</li><li>user completing a video watch is a positive example.</li><li><a href=https://www.tensorflow.org/extras/candidate_sampling.pdf>candidate sampling</a> & <a href=https://en.wikipedia.org/wiki/Importance_sampling>importance weighting</a> is used to sample negative examples.</li></ul></li><li><p>Embeddings describing the watch history, user query, demographics, etc are fed to a simple feed-forward neural network having a final softmax layer to learn the class probabilities.</p><ul><li><strong>watch history</strong>: dense vector representation of watched video is learned from a sequence of video-ids (just like word2vec).</li><li><strong>user query</strong>: n-gram representations</li><li><strong>demographics</strong>: geographic region, device, age, etc. are used as numerical/categorical features</li></ul></li><li><p>The embeddings are jointly learned while training the model via gradient descent back-propagation.</p></li><li><p>Age of the video is used to model the time-dependent nature of popular videos. Otherwise, the good old popular videos are going to be selected most of the times, isn&rsquo;t it?</p></li><li><p>What&rsquo;s interesting is that a lot of features were &ldquo;engineered&rdquo; as opposed to the promise of deep learning to reduce it.</p></li><li><p><strong>Training data & label:</strong></p><ul><li>There&rsquo;s an inherent sequence of video consumption. Hence, using random held-out data will be cheating since future information will leak into the training process. The model will overfit! Think about time-series forecasting. A random train-test split won&rsquo;t work since the future data is not available in production during serving time.
<img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1630225522918/zoyaMC-Ae.png alt="Screenshot 2021-08-29 at 1.55.18 PM.png"></li><li>The authors propose a model of predicting <em>user&rsquo;s next watch</em> instead of a randomly held-out watch. This makes sense, as we consume videos in a sequence. For example, if you&rsquo;re watching a series with several episodes, recommending a random episode from that series doesn&rsquo;t make sense.
<img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1630225542842/UAGeaWt8C.png alt="Screenshot 2021-08-29 at 1.55.39 PM.png"></li></ul></li><li><p><strong>Serving:</strong></p><ul><li>To score millions of videos in latency of tens of milliseconds, a nearest neighbor-based search algorithm is used. Exact probability values of softmax() are not required. Hence, a dot product of user and video embeddings could be used to figure out the propensity score of a user <em>u</em> for a particular video <em>v_i</em>. A nearest neighbor search algorithm could be used to figure out the top K candidate videos based on the score.</li></ul></li></ul><h3 id=ranking>Ranking</h3><p><img src=https://cdn.hashnode.com/res/hashnode/image/upload/v1630229225282/zDkuTAg45.png alt="Screenshot 2021-08-29 at 2.56.54 PM.png"></p><ul><li>Candidate generation selects a few hundred out of millions of videos. The ranking procedure could make use of more video features as well as user&rsquo;s interactions with it in order to figure out an order of recommendation.</li><li>The model architecture is similar to the candidate generation procedure. We assign a score to the videos using weighted logistic regression.</li><li>The objective to optimize is a function of expected watch time per impression.</li><li>Why not click-through rate? Well, that would promote clickbait videos instead of quality content. Watch time is a better signal that captures engagement.</li><li><strong>Modeling Expected Watch Time</strong><ul><li><strong>Objective</strong>: Predict expected watch time for a given video.</li><li><strong>Model</strong>: Weighted Logistic Regression, since the class distributions are imbalanced.<ul><li><strong>Positive example</strong>: the video was watched.</li><li><strong>Negative example</strong>: the video was not clicked.</li></ul></li><li>**What are the weights in &ldquo;weighted&rdquo; logistic regression? **<ul><li>Positive examples are weighted by the watch time.</li><li>Negative examples are given a weight of 1.</li></ul></li><li><strong>Loss</strong>: cross-entropy</li></ul></li></ul><h2 id=references>References</h2><ol><li><a href=https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf>Deep Neural Networks for YouTube Recommendations</a></li><li><a href=https://en.wikipedia.org/wiki/Softmax_function>Softmax</a></li></ol></article></div></div><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><hr></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-2"></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><section id=social-share><div class="list-inline footer-links"><div class=share-box aria-hidden=true><div><p class="list-inline footer-links">Use the share button below if you liked it.</p></div><ul class=share><li><a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fsaikatkumardey.com%2fpost%2fdeep-nn-for-youtube-recommendations%2f" target=_blank title="Share on Facebook"><i class="bi bi-facebook facebook-color"></i></a></li><li><a href="//twitter.com/share?url=https%3a%2f%2fsaikatkumardey.com%2fpost%2fdeep-nn-for-youtube-recommendations%2f&amp;text=Deep%20Neural%20Networks%20for%20YouTube%20Recommendations&amp;via=map%5bemail%3asample%40gmail.com%20facebook%3ausername%20github%3asaikatkumardey%20linkedin%3asaikatkumardey%20name%3aSaikat%20Kumar%20Dey%20twitter%3asaikatkrdey%20website%3ahttps%3a%2f%2fsaikatkumardey.com%2f%20youtube%3a%5d" target=_blank title="Share on Twitter"><i class="bi bi-twitter twitter-color"></i></a></li><li><a href="//reddit.com/submit?url=https%3a%2f%2fsaikatkumardey.com%2fpost%2fdeep-nn-for-youtube-recommendations%2f&amp;title=Deep%20Neural%20Networks%20for%20YouTube%20Recommendations" target=_blank title="Share on Reddit"><i class="bi bi-reddit reddit-color"></i></a></li><li><a href="whatsapp://send?text=https%3a%2f%2fsaikatkumardey.com%2fpost%2fdeep-nn-for-youtube-recommendations%2f&amp;description=Deep%20Neural%20Networks%20for%20YouTube%20Recommendations" target=_blank rel=noopener title="Share on WhatsApp"><i class="bi bi-whatsapp whatsapp-color"></i></a></li></ul></div></div></section></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><ul class="list-group list-group-horizontal" style=flex-direction:row><li class="list-group-item b-0"><a type=button class="btn btn-dark" role=button href=https://saikatkumardey.com/post/predictive-model-performance-online-and-offline-eval/ data-toggle=tooltip data-placement=top title="Predictive Model Performance Online and Offline Eval">&larr;
Previous Post</a></li><li class="list-group-item ms-auto b-0"><a type=button class="btn btn-dark" role=button href=https://saikatkumardey.com/post/a-simplified-implementation-of-quicksort/ data-toggle=tooltip data-placement=top title="A Simplified Implementation of Quicksort">Next Post
&rarr;</a></li></ul></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"></div></div></div><div><div class=container><div class=row></div></div></div></div></div><footer><div class=container><div class=row><div class=col-md-12><ul class="list-inline list-group list-group-horizontal text-center footer-links d-flex justify-content-center flex-row"><li><a href=mailto:sample@gmail.com title="Email me" target=_blank><span class=mx-2><i class="bi bi-envelope"></i></span></a></li><li><a href=https://www.facebook.com/username title=Facebook target=_blank><span class=mx-2><i class="bi bi-facebook"></i></span></a></li><li><a href=https://github.com/saikatkumardey title=GitHub target=_blank><span class=mx-2><i class="bi bi-github"></i></span></a></li><li><a href=https://twitter.com/saikatkrdey title=Twitter target=_blank><span class=mx-2><i class="bi bi-twitter"></i></span></a></li><li><a href=https://linkedin.com/in/saikatkumardey title=LinkedIn target=_blank><span class=mx-2><i class="bi bi-linkedin"></i></span></a></li><li><a href=https://www.youtube.com/ title=Youtube target=_blank><span class=mx-2><i class="bi bi-youtube"></i></span></a></li></ul></div></div><div class=row><div class=col-md-12><p class="credits copyright text-muted"><a href=https://saikatkumardey.com/>Saikat Kumar Dey</a>
&nbsp;&bull;&nbsp;&copy;
2023
&nbsp;&bull;&nbsp;
<a href=https://saikatkumardey.com>Saikat Kumar Dey</a></p><p class="credits theme-by text-muted">Powered by <a href=https://gohugo.io>Hugo</a> & <a href=https://github.com/binokochumolvarghese/lightbi-hugo>Lightbi.</a>&nbsp; Made with ‚ù§ by <a href=https://binovarghese.com>Bino</a></p></div></div></div></footer><script src=https://code.jquery.com/jquery-3.7.0.slim.min.js integrity="sha256-tG5mcZUtJsZvyKAxYLVXrmjKBVLd6VpVccqz/r4ypFE=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha3/dist/js/bootstrap.min.js integrity=sha384-Y4oOpwW3duJdCWv5ly8SCFYWqFDsfob/3GkgExXKV4idmbt98QcxXYs9UoXAB7BZ crossorigin=anonymous></script>
<script src=https://saikatkumardey.com/js/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script>$(document).ready(function(){$("pre.chroma").css("padding","0")})</script><script src=https://saikatkumardey.com/js/dark-mode.js></script></body></html>