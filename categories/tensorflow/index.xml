<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tensorflow on Saikat Kumar Dey</title><link>https://saikatkumardey.com/categories/tensorflow/</link><description>tensorflow</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Sat, 25 Jun 2022 13:06:10 +0530</lastBuildDate><atom:link href="https://saikatkumardey.com/categories/tensorflow/index.xml" rel="self" type="application/rss+xml"/><item><title>Training Image Classification Models with scikeras</title><link>https://saikatkumardey.com/posts/scikeras/</link><pubDate>Sat, 25 Jun 2022 13:06:10 +0530</pubDate><guid>https://saikatkumardey.com/posts/scikeras/</guid><description>&lt;h2 id="introduction-to-scikeras">Introduction to scikeras&lt;/h2>
&lt;p>Scikeras is a powerful tool that allows users to combine the capabilities of TensorFlow and scikit-learn in order to train deep learning models. By using scikeras, users can take advantage of the strengths of both TensorFlow and scikit-learn, and benefit from the ease of use and flexibility of scikit-learn&amp;rsquo;s API.&lt;/p>
&lt;p>In this blog post, we will demonstrate how to use scikeras to train a model using a large dataset of images stored on disk. We will show how to use TensorFlow&amp;rsquo;s &lt;code>ImageDataGenerator()&lt;/code> function to load images in batches and apply real-time augmentation, and how to use scikeras&amp;rsquo;s &lt;code>KerasClassifier()&lt;/code> to create a scikit-learn compatible interface for training the model. We will also demonstrate how to use &lt;code>partial_fit()&lt;/code> to train the model on smaller batches of data and retain the history of model weights and parameters.&lt;/p>
&lt;h2 id="download-dataset">Download dataset&lt;/h2>
&lt;p>Download a sample &lt;a href="https://www.kaggle.com/datasets/muratkokludataset/pistachio-image-dataset">dataset&lt;/a> and store the dataset in &lt;code>data/&lt;/code>. Your directory structure should look like the following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-fallback" data-lang="fallback">&lt;span style="display:flex;">&lt;span>data/Pistachio_Image_Dataset
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>├── Kirmizi_Pistachio/*.jpg
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>└── Siirt_Pistachio/*.jpg
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="import-necessary-libraries">Import necessary libraries&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">from&lt;/span> &lt;span style="color:#000">math&lt;/span> &lt;span style="color:#a90d91">import&lt;/span> &lt;span style="color:#000">ceil&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">import&lt;/span> &lt;span style="color:#000">tensorflow&lt;/span> &lt;span style="color:#a90d91">as&lt;/span> &lt;span style="color:#000">tf&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">from&lt;/span> &lt;span style="color:#000">matplotlib&lt;/span> &lt;span style="color:#a90d91">import&lt;/span> &lt;span style="color:#000">pyplot&lt;/span> &lt;span style="color:#a90d91">as&lt;/span> &lt;span style="color:#000">plt&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">from&lt;/span> &lt;span style="color:#000">scikeras.wrappers&lt;/span> &lt;span style="color:#a90d91">import&lt;/span> &lt;span style="color:#000">KerasClassifier&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">from&lt;/span> &lt;span style="color:#000">tensorflow.keras.preprocessing.image&lt;/span> &lt;span style="color:#a90d91">import&lt;/span> &lt;span style="color:#000">ImageDataGenerator&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="setup-constants">Setup Constants&lt;/h2>
&lt;p>Next, we need to set some constants that will be used throughout the training process. In this example, we will be using a batch size of 32 and training the model for 10 epochs. You may need to adjust these values depending on your dataset and the performance of your model.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">DATA_DIR&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#c41a16">&amp;#34;data/Pistachio_Image_Dataset&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">BATCH_SIZE&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#1c01ce">32&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">EPOCHS&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#1c01ce">10&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="loader-for-reading-data-in-batches">Loader for reading data in batches&lt;/h2>
&lt;p>One of the key advantages of using scikeras is the ability to train a model using large datasets that do not fit into memory. To do this, we can use TensorFlow&amp;rsquo;s &lt;code>ImageDataGenerator()&lt;/code> function to load images in batches and apply real-time augmentation. This allows us to train the model on smaller chunks of the dataset, without having to load the entire dataset into memory.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">image_generator&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#000">ImageDataGenerator&lt;/span>(&lt;span style="color:#000">rescale&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#1c01ce">1.0&lt;/span> &lt;span style="color:#000">/&lt;/span> &lt;span style="color:#1c01ce">255&lt;/span>)&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">flow_from_directory&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">DATA_DIR&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">target_size&lt;/span>&lt;span style="color:#000">=&lt;/span>(&lt;span style="color:#1c01ce">32&lt;/span>, &lt;span style="color:#1c01ce">32&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">batch_size&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">BATCH_SIZE&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">class_mode&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#c41a16">&amp;#34;binary&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">total_images&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#a90d91">len&lt;/span>(&lt;span style="color:#000">image_generator&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">filenames&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">total_batches&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#000">ceil&lt;/span>(&lt;span style="color:#000">total_images&lt;/span> &lt;span style="color:#000">//&lt;/span> &lt;span style="color:#000">BATCH_SIZE&lt;/span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this code, we are using ImageDataGenerator() to create a generator that will load the images in DATA_DIR in batches of size BATCH_SIZE, apply a rescaling factor of 1/255, and return the images and labels in a binary format. We then calculate the total number of images in the dataset and the total number of batches. These values will be used later in the training loop.&lt;/p>
&lt;h2 id="define-your-tensorflow-model-architecture">Define your Tensorflow model architecture&lt;/h2>
&lt;p>Next, we need to define the architecture of our TensorFlow model. For the purposes of this example, we will be using a simple shallow-net with a single dense layer. However, you can use any architecture that you prefer, and you can experiment with different architectures to see which one performs best on your dataset.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">model&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#000">tf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">keras&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">Sequential&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">tf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">keras&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">layers&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">Input&lt;/span>(&lt;span style="color:#000">shape&lt;/span>&lt;span style="color:#000">=&lt;/span>(&lt;span style="color:#1c01ce">32&lt;/span>, &lt;span style="color:#1c01ce">32&lt;/span>, &lt;span style="color:#1c01ce">3&lt;/span>)),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">tf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">keras&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">layers&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">Flatten&lt;/span>(),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">tf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">keras&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">layers&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">Dense&lt;/span>(&lt;span style="color:#1c01ce">1&lt;/span>, &lt;span style="color:#000">activation&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#c41a16">&amp;#34;sigmoid&amp;#34;&lt;/span>),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="define-scikeras-interface">Define scikeras interface&lt;/h2>
&lt;p>Once we have defined our TensorFlow model, we can use scikeras&amp;rsquo;s KerasClassifier() function to create a scikit-learn compatible interface for training the model. This allows us to use the familiar fit() and predict() methods from scikit-learn, while taking advantage of the capabilities of TensorFlow.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">sk_clf&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#000">KerasClassifier&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">model&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#000">model&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">optimizer&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#c41a16">&amp;#34;adam&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">loss&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#c41a16">&amp;#34;binary_crossentropy&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">metrics&lt;/span>&lt;span style="color:#000">=&lt;/span>[&lt;span style="color:#c41a16">&amp;#34;accuracy&amp;#34;&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this code, we are creating a KerasClassifier object and passing it our TensorFlow model, as well as some other parameters such as the optimizer and loss function to use during training. We are also specifying that we want to track the accuracy metric during training. You can adjust these parameters as needed to suit your specific use.&lt;/p>
&lt;h2 id="training-loop">Training loop&lt;/h2>
&lt;p>Now that we have set up the necessary components for training our model, we can implement the main training loop. This loop will iterate over the batches of images generated by &lt;code>ImageDataGenerator()&lt;/code>, and will use &lt;code>partial_fit()&lt;/code> to train the model on each batch. &lt;code>partial_fit()&lt;/code> has the advantage of allowing us to train the model on smaller batches of data, and it also retains the history of model weights and parameters, whereas &lt;code>fit()&lt;/code> resets this history every time it is called.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">batch&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#1c01ce">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">epoch&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#1c01ce">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#000">histories&lt;/span> &lt;span style="color:#000">=&lt;/span> []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a90d91">for&lt;/span> &lt;span style="color:#000">X&lt;/span>, &lt;span style="color:#000">y&lt;/span> &lt;span style="color:#000">in&lt;/span> &lt;span style="color:#000">image_generator&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">sk_clf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">partial_fit&lt;/span>(&lt;span style="color:#000">X&lt;/span>, &lt;span style="color:#000">y&lt;/span>, &lt;span style="color:#000">verbose&lt;/span>&lt;span style="color:#000">=&lt;/span>&lt;span style="color:#a90d91">False&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">history&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#000">sk_clf&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">model_&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">history&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">history&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">histories&lt;/span>&lt;span style="color:#000">.&lt;/span>&lt;span style="color:#000">append&lt;/span>(&lt;span style="color:#000">history&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">batch&lt;/span> &lt;span style="color:#000">+=&lt;/span> &lt;span style="color:#1c01ce">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a90d91">if&lt;/span> &lt;span style="color:#000">batch&lt;/span> &lt;span style="color:#000">==&lt;/span> &lt;span style="color:#000">total_batches&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">batch&lt;/span> &lt;span style="color:#000">=&lt;/span> &lt;span style="color:#1c01ce">0&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#000">epoch&lt;/span> &lt;span style="color:#000">+=&lt;/span> &lt;span style="color:#1c01ce">1&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a90d91">print&lt;/span>(
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#c41a16">f&lt;/span>&lt;span style="color:#c41a16">&amp;#34;epoch &lt;/span>&lt;span style="color:#c41a16">{&lt;/span>&lt;span style="color:#000">epoch&lt;/span>&lt;span style="color:#c41a16">}&lt;/span>&lt;span style="color:#c41a16">/&lt;/span>&lt;span style="color:#c41a16">{&lt;/span>&lt;span style="color:#000">EPOCHS&lt;/span>&lt;span style="color:#c41a16">}&lt;/span>&lt;span style="color:#c41a16">, loss &lt;/span>&lt;span style="color:#c41a16">{&lt;/span>&lt;span style="color:#000">history&lt;/span>[&lt;span style="color:#c41a16">&amp;#39;loss&amp;#39;&lt;/span>][&lt;span style="color:#1c01ce">0&lt;/span>]&lt;span style="color:#c41a16">}&lt;/span>&lt;span style="color:#c41a16"> accuracy &lt;/span>&lt;span style="color:#c41a16">{&lt;/span>&lt;span style="color:#000">history&lt;/span>[&lt;span style="color:#c41a16">&amp;#39;accuracy&amp;#39;&lt;/span>][&lt;span style="color:#1c01ce">0&lt;/span>]&lt;span style="color:#c41a16">}&lt;/span>&lt;span style="color:#c41a16">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a90d91">if&lt;/span> &lt;span style="color:#000">epoch&lt;/span> &lt;span style="color:#000">==&lt;/span> &lt;span style="color:#000">EPOCHS&lt;/span>:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a90d91">break&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In this code, we are looping over the batches generated by ImageDataGenerator() and calling partial_fit() on each batch. We are also keeping track of the history of model weights and parameters, and we are printing the loss and accuracy for each epoch. Once we have reached the specified number of epochs, the training loop will exit and the model will be trained. At this point, you can use the &lt;code>predict()&lt;/code> method to make predictions on new data, or you can continue training the model using &lt;code>partial_fit()&lt;/code> to improve its performance further.&lt;/p>
&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In this blog post, we have demonstrated how to use scikeras to train a TensorFlow model on a large dataset of images stored on disk. We have shown how to use &lt;code>ImageDataGenerator()&lt;/code> to load images in batches and apply real-time augmentation, how to use &lt;code>KerasClassifier()&lt;/code> to create a scikit-learn compatible interface for training the model, and how to use &lt;code>partial_fit()&lt;/code> to train the model on smaller batches of data and retain the history of model weights and parameters.&lt;/p>
&lt;p>Overall, scikeras is a convenient and effective tool for training image classification models, and it allows users to take advantage of the strengths of both TensorFlow and scikit-learn. There are many potential avenues for further improvement, such as experimenting with different model architectures, fine-tuning the training parameters, and applying more advanced augmentation techniques. We hope that this blog post has provided a useful introduction to scikeras and has given you some ideas for how to use it in your own projects.&lt;/p></description></item></channel></rss>