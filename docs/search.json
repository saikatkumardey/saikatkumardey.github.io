[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "",
    "text": "Life moves fast, my friends - faster than we realize. Before you know it, your days and years will be gone. Each moment is a gift, so how are you gonna spend it? Floating along or diving in? Arnold Bennett says too many of us squander our time on distraction and leisure. But life’s meant for living! Don’t just sit there - get up and seize the day."
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html#follow-your-curiosity-and-passion",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html#follow-your-curiosity-and-passion",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "Follow Your Curiosity and Passion",
    "text": "Follow Your Curiosity and Passion\nWe’ve only got so much time in this world, so pursue what fires you up! Learn a new skill, discover a hobby, create something. Don’t miss out on life’s adventures. Wake up that brain of yours and see what it can do! And exercise your body too - your health is up to you. Take it from me, life’s too short to waste on laziness or boredom. There’s a whole world of interesting stuff out there - so go get curious!"
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html#renew-your-purpose",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html#renew-your-purpose",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "Renew Your Purpose",
    "text": "Renew Your Purpose\nIt’s easy to get stuck in a rut, doing the same old routine each day. Shake up your schedule and do something different. Go for a hike. Call up some friends for a real conversation. Take time to reflect on what gives life deep meaning and purpose for you. Think about the legacy you want to leave behind. A life well lived doesn’t just happen - you have to craft it."
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html#stop-delaying-and-start-doing",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html#stop-delaying-and-start-doing",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "Stop Delaying and Start Doing",
    "text": "Stop Delaying and Start Doing\nThe time we get is limited and swift, so stop delaying and start doing! Follow your passions, engage with life, waste less time on the trivial and meaningless. Sure, it’s easy to make excuses - but one day you’ll wake up and realize your chance to live boldly has passed you by."
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html#wake-up-to-the-gift-of-time",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html#wake-up-to-the-gift-of-time",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "Wake Up to the Gift of Time",
    "text": "Wake Up to the Gift of Time\nGrowth and purpose, adventure and passion - that’s what life’s about. The choice is yours: sit on the sidelines or play full out. Don’t wait for some day down the road - that day is now. Wake up to each moment and make it count. Bennett is telling us to open our eyes to the gift of time and live like there’s no tomorrow. I say he’s got it right. This spinning world keeps turning - so get on your feet and turn with it! Make each day an opportunity for discovery and growth. Your future self will be glad you did."
  },
  {
    "objectID": "posts/12-how-to-live-on-24-hours-a-day.html#craft-a-life-with-meaning",
    "href": "posts/12-how-to-live-on-24-hours-a-day.html#craft-a-life-with-meaning",
    "title": "How to Live on 24 Hours a Day by Arnold Bennett",
    "section": "Craft a Life With Meaning",
    "text": "Craft a Life With Meaning\nLife moves fast, but living purposefully can help us slow it down and make each moment matter. Seize your chance to turn inspiration into action and purpose into meaning. There are no do-overs - just the moments and days we have right now. Your time, and how you choose to spend it - that’s the adventure. So what do you say, friends - are you gonna sit there or live like you mean it? The clock’s ticking! Now get out there and make your days count."
  },
  {
    "objectID": "posts/7-building-pandas-dataframes-from-ndarrays.html",
    "href": "posts/7-building-pandas-dataframes-from-ndarrays.html",
    "title": "Building Pandas Dataframes From Ndarrays",
    "section": "",
    "text": "At work, I have to switch between numpy & pandas depending on the computational needs. Numpy is faster. Pandas is easier to work with.\nOne of the tasks I’ve faced often was to convert a 3-dimensional ndarray to a pandas dataframe. I will share my preferred technique in this post today.\nFor the purpose of this exercise, I’ll generate dummy sales data for a retail company. The dimensions include products, locations, and sales."
  },
  {
    "objectID": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-sales",
    "href": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-sales",
    "title": "Building Pandas Dataframes From Ndarrays",
    "section": "1d : dimension = sales",
    "text": "1d : dimension = sales\nLet’s start with 1d data. What if we only had sales info for all products and locations?\narr_1d = np.random.randint(\n    low=1,\n    high=10,\n    size=3,\n)\nprint(arr_1d)\n[9 3 6]\nThat’s easy. Ideally, 1-d information should be represented as a Series.\ndf_1d = pd.DataFrame(arr_1d, columns=[\"sales\"])\nprint(df_1d)\n   sales\n0      9\n1      3\n2      6"
  },
  {
    "objectID": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-sales-product",
    "href": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-sales-product",
    "title": "Building Pandas Dataframes From Ndarrays",
    "section": "2d: dimension = sales * product",
    "text": "2d: dimension = sales * product\nLet’s move on to 2 dimensions. Now, we have data corresponding to different products.\narr_2d = np.random.randint(\n    low=1,\n    high=10,\n    size=(3, 2),\n)\nprint(arr_2d)\n[[4 6]\n [8 1]\n [2 7]]\nPandas DataFrame can handle 2-D ndarrays out of the box.\ndf_2d = pd.DataFrame(arr_2d, columns=[\"product\", \"sales\"]).set_index(\"product\")\nprint(df_2d)\n         sales\nproduct\n4            6\n8            1\n2            7"
  },
  {
    "objectID": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-location-x-product-x-sales",
    "href": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-location-x-product-x-sales",
    "title": "Building Pandas Dataframes From Ndarrays",
    "section": "3d : dimension = location x product x sales",
    "text": "3d : dimension = location x product x sales\nNow, what if we have a ndarray corresponding to all products for several locations?\n# failure\narr_3d = np.random.randint(\n    low=1,\n    high=10,\n    size=(5, 3, 1),\n)\nprint(arr_3d)\n[[[9]\n  [6]\n  [2]]\n\n [[1]\n  [4]\n  [4]]\n\n [[2]\n  [5]\n  [6]]\n\n [[9]\n  [6]\n  [5]]\n\n [[1]\n  [6]\n  [1]]]\n# the following raises ValueError\n# pandas DataFrame expects a 2-d input\ndf_3d = pd.DataFrame(arr_3d, columns=[\"location\", \"product\", \"sales\"])\npandas won’t work out of the box. It cannot handle more than 2 dimensions. So, it raises a ValueError.\n    ---------------------------------------------------------------------------\n\n\n    ValueError                                Traceback (most recent call last)\n\n    /var/folders/jq/ksxbjg7d58g9v9rrcl0f38380000gn/T/ipykernel_12628/1531564731.py in &lt;module&gt;\n          1 # the following raises ValueError\n          2 # pandas DataFrame expects a 2-d input\n    ----&gt; 3 df_3d = pd.DataFrame(arr_3d, columns=[\"location\", \"product\", \"sales\"])\n    .\n    .\n    .\n    ValueError: Must pass 2-d input. shape=(5, 3, 1)\nThe solution?\nMultiIndex.\nAssuming that the ndarray is ordered by location/products, we could prepare a multi-index, flatten our ndarray and let Pandas reshape it according to the provided index.\nSweet!\nindex = pd.MultiIndex.from_product(\n    [range(dim) for dim in arr_3d.shape[:-1]],\n    names=[\"location\", \"product\"],\n)\n\ndf_3d = pd.DataFrame(arr_3d.flatten(), index=index, columns=[\"sales\"])\nprint(df_3d)\n                  sales\nlocation product\n0        0            9\n         1            6\n         2            2\n1        0            1\n         1            4\n         2            4\n2        0            2\n         1            5\n         2            6\n3        0            9\n         1            6\n         2            5\n4        0            1\n         1            6\n         2            1\nWe just have sales corresponding to each location and product. What if the final sales dimension includes sales for yesterday/today (or for every month, every week, etc.) ?"
  },
  {
    "objectID": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-location-x-product-x-sales-multi",
    "href": "posts/7-building-pandas-dataframes-from-ndarrays.html#d-dimension-location-x-product-x-sales-multi",
    "title": "Building Pandas Dataframes From Ndarrays",
    "section": "3d : dimension = location x product x sales (multi)",
    "text": "3d : dimension = location x product x sales (multi)\narr_3d = np.random.randint(\n    low=1,\n    high=10,\n    size=(5, 3, 2),\n)\nprint(arr_3d)\nindex = pd.MultiIndex.from_product(\n    [range(dim) for dim in arr_3d.shape],\n    names=[\"location\", \"product\", \"sales\"],\n)\n[[[1 9]\n  [8 6]\n  [9 4]]\n\n [[4 9]\n  [3 9]\n  [1 8]]\n\n [[5 2]\n  [9 9]\n  [1 9]]\n\n [[4 5]\n  [7 4]\n  [7 7]]\n\n [[6 9]\n  [4 2]\n  [7 1]]]\nNo major changes. Pandas should handle it just like before. Just unstack the sales dimension and rename the columns for readability.\ndf_3d = pd.DataFrame(\n    arr_3d.flatten(),\n    index=index,\n    columns=[\"sales\"],\n)\ndf_3d = df_3d.unstack(-1).rename(\n    columns={0: \"yesterday\", 1: \"today\"},\n)\nprint(df_3d)\n    sales            yesterday today\n    location product\n    0        0               1     9\n             1               8     6\n             2               9     4\n    1        0               4     9\n             1               3     9\n             2               1     8\n    2        0               5     2\n             1               9     9\n             2               1     9\n    3        0               4     5\n             1               7     4\n             2               7     7\n    4        0               6     9\n             1               4     2\n             2               7     1\nDo you know of other ways to switch between ndarray and DataFrame? Comment below :)"
  },
  {
    "objectID": "posts/8-claude+langchain+youtube.html",
    "href": "posts/8-claude+langchain+youtube.html",
    "title": "I summarised a 3 hour long youtube video using Langchain + Claude",
    "section": "",
    "text": "I used Langchain + Claude to summarise Sam Altman’s testimony to the US Senate on AI. The video is 3 hours long and the transcript has about 30k+ tokens. I used Langchain to extract the transcript and Claude to summarise it. The result is a 1 page summary of the key points from the video. I have included the summary, code, and prompt below.\nTech:"
  },
  {
    "objectID": "posts/8-claude+langchain+youtube.html#prompt",
    "href": "posts/8-claude+langchain+youtube.html#prompt",
    "title": "I summarised a 3 hour long youtube video using Langchain + Claude",
    "section": "Prompt",
    "text": "Prompt\n\"\"\"\nPlease write a professional summary with a beginning, middle, and end based on the video transcript.\n\nInstructions\n\n- Do not include any details that are not mentioned in the video.\n- Use bullet points and section headers to organize your summary.\n- Do not include any personal opinions or thoughts.\n- Include title, introduction, witnesses, their testimonies, key takeaways and conclusion.\n\n\nVideo transcript:\n\"\"\""
  },
  {
    "objectID": "posts/8-claude+langchain+youtube.html#summary",
    "href": "posts/8-claude+langchain+youtube.html#summary",
    "title": "I summarised a 3 hour long youtube video using Langchain + Claude",
    "section": "Summary",
    "text": "Summary\n\nHere is a professional summary of the key points from the Senate hearing on AI oversight:\n\n# Senate Hearing on AI Oversight - May 16, 2023\n\n## Witnesses\n\n- Sam Altman, CEO of OpenAI\n- Christina Montgomery, IBM's Vice President and Chief Privacy and Trust Officer\n- Gary Marcus, AI scientist and entrepreneur\n\n## Key Takeaways\n\n- AI has the potential for both great benefits and substantial risks. Proper oversight and regulation are needed to maximize the benefits while mitigating the risks.\n\n- Witnesses recommend a combination of self-regulation by AI companies and government regulation to ensure trustworthy and safe AI.\n\n- High-risk uses of AI, such as those impacting elections, medical advice, and national security, should face the strictest oversight and regulation.\n\n- Transparency, accountability, and limits on certain AI capabilities are seen as important principles for a regulatory framework.\n\n- An independent agency focused on AI may be needed to keep up with the rapid pace of AI development. However, proper resources and expertise will be critical for such an agency to be effective.\n\n- International coordination will also be important given the global nature of AI development and risks. The U.S. should take a leadership role in setting responsible AI standards.\n\n## Conclusion\n\nThe hearing highlighted both the promise and potential pitfalls of generative AI. While witnesses differed in some details, there was broad agreement that a combination of self-regulation, government oversight, and international coordination will be essential to maximize the benefits of AI technologies while mitigating the risks. The Senate considers this hearing as the first step in developing appropriate policies and safeguards for AI."
  },
  {
    "objectID": "posts/8-claude+langchain+youtube.html#code",
    "href": "posts/8-claude+langchain+youtube.html#code",
    "title": "I summarised a 3 hour long youtube video using Langchain + Claude",
    "section": "Code",
    "text": "Code\nimport argparse\nimport os\n\nimport anthropic\nfrom langchain.document_loaders import YoutubeLoader\n\n\ndef load_transcript(url):\n    loader = YoutubeLoader.from_youtube_url(\n        url,\n        add_video_info=True,\n    )\n    docs = loader.load()\n    if len(docs) == 0:\n        raise ValueError(\"Sorry, No transcript found.😢\")\n    return docs[0]\n\n\ndef write_summary(doc):\n\n    anthropic_key = os.getenv(\"ANTHROPIC_KEY\")\n\n    client = anthropic.Client(anthropic_key)\n\n    prompt = f\"\"\"\nPlease write a professional summary with a beginning, middle, and end based on the video transcript.\n\nInstructions\n\n- Do not include any details that are not mentioned in the video.\n- Use bullet points and section headers to organize your summary.\n- Do not include any personal opinions or thoughts.\n- Include title, introduction, witnesses, their testimonies, key takeaways and conclusion.\n\n\nVideo transcript:\n\n{doc.dict()}\n\n\"\"\"\n    prompt_formatted = (\n        f\"{anthropic.HUMAN_PROMPT}{prompt}\\n{anthropic.AI_PROMPT}\"\n    )\n    response = client.completion(\n        prompt=prompt_formatted,\n        stop_sequences=[anthropic.HUMAN_PROMPT],\n        model=\"claude-instant-v1-100k\",\n        max_tokens_to_sample=100000,\n        temperature=0.3,\n    )\n    return response[\"completion\"]\n\n\ndef main():\n\n    parser = argparse.ArgumentParser(\n        description=\"Write a professional summary based on a YouTube video transcript.\"\n    )\n    parser.add_argument(\"url\", type=str, help=\"The YouTube URL of the video.\")\n    args = parser.parse_args()\n    try:\n        doc = load_transcript(args.url)\n        summary = write_summary(doc)\n        print(summary)\n    except Exception as e:\n        print(e)\n\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
    "objectID": "posts/8-claude+langchain+youtube.html#run-the-script",
    "href": "posts/8-claude+langchain+youtube.html#run-the-script",
    "title": "I summarised a 3 hour long youtube video using Langchain + Claude",
    "section": "Run the script",
    "text": "Run the script\n\nFirst install the required packages:\n\npip install anthropic langchain\n\nThen set the ANTHROPIC_KEY environment variable to your API key obtained from Anthropic Console.\nRun this script with the following command:\n\npython3 main.py https://www.youtube.com/watch/?v=fP5YdyjTfG0\nFun fact: Bing Chat (GPT-4) helped me organise my dirty notebook into a nice CLI script which I share with you all today."
  },
  {
    "objectID": "posts/17-ollama.html",
    "href": "posts/17-ollama.html",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "",
    "text": "Thanks to ChatGPT, almost everyone has heard of Large language models (LLMs) in some form or other. LLMs are large neural networks trained on large amounts of data to perform a variety of tasks. They are the backbone of many NLP applications today.\nWhile the power of Large Language Models (LLMs) is undeniable, their use often involves reliance on cloud services. This not only raises concerns about data privacy but also exposes users to potential censorship. What if you could harness the power of LLMs right on your laptop, ensuring your data privacy and freedom from censorship?\nEnter Ollama.ai, an open-source project that brings LLMs to your personal computer. It provides a Docker-like interface for LLMs, allowing you to run these models locally, keeping your data private and secure.\nIn this blog post, we’ll guide you through the process of using Ollama to run LLMs on your laptop. Let’s get started!"
  },
  {
    "objectID": "posts/17-ollama.html#why-run-llms-locally",
    "href": "posts/17-ollama.html#why-run-llms-locally",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "Why run LLMs locally?",
    "text": "Why run LLMs locally?\nThere are several reasons why running LLMs locally is important:\n\nFreedom: Running LLMs locally means you don’t have to rely on cloud services, which can be costly and may expose you to censorship. You don’t really want to be lectured by a model, do you?\nPrivacy: Your data stays on your laptop, so you can be sure that no one else can access it.\nControl: Running LLMs locally gives you more control over the model, prompt, and other parameters."
  },
  {
    "objectID": "posts/17-ollama.html#what-is-ollama.ai-and-how-does-it-help",
    "href": "posts/17-ollama.html#what-is-ollama.ai-and-how-does-it-help",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "What is Ollama.ai and how does it help?",
    "text": "What is Ollama.ai and how does it help?\nOllama is an open-source project that enables you to execute LLMs on your laptop or server, offering a Docker-like interface for LLMs. It includes a straightforward CLI for managing and experimenting with LLMs, and a server that allows interaction via a simple API. This can also be accessed from Langchain.\nOllama is built on GGUF/GGML models, which can be easily created using the llama.cpp project. These models are heavily quantized and optimized for inference on your Mac’s built-in GPU, and they also work on CUDA GPUs.\nYou can find GGUF/GGML models on huggingface, with the latest models typically available at TheBloke."
  },
  {
    "objectID": "posts/17-ollama.html#how-does-ollama.ai-facilitate-running-llms",
    "href": "posts/17-ollama.html#how-does-ollama.ai-facilitate-running-llms",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "How does Ollama.ai facilitate running LLMs?",
    "text": "How does Ollama.ai facilitate running LLMs?\nIt can be downloaded and installed from here. The installation process is simple and user-friendly, with a GUI available for Mac users. Linux users can install Ollama.ai by running the following command:\ncurl https://ollama.ai/install.sh | sh\nNote that Windows support is currently unavailable."
  },
  {
    "objectID": "posts/17-ollama.html#where-to-find-supported-llms",
    "href": "posts/17-ollama.html#where-to-find-supported-llms",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "Where to find supported LLMs?",
    "text": "Where to find supported LLMs?\n\n\nOllama maintains a library of supported LLMs. You can also create & run a custom LLM from any GGUF model from huggingface."
  },
  {
    "objectID": "posts/17-ollama.html#how-to-run-llms-with-ollama",
    "href": "posts/17-ollama.html#how-to-run-llms-with-ollama",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "How to run LLMs with Ollama?",
    "text": "How to run LLMs with Ollama?\nYou can run one of the supported models from the Ollama library using ollama run {model:tag}. Let’s try running the samantha-mistral model from the library:\n\nSamantha is a conversational model created by Eric Hartford. Samantha is trained in philosophy, psychology, and personal relationships.\n\n❯ ollama run samantha-mistral\n\n\n&gt;&gt;&gt; I feel disconnected from the world\n\nIt can be difficult when you're feeling disconnected from the world. One thing\nto consider is engaging in activities or social interactions that help you feel\nmore connected and present. This might involve spending time with friends or\nfamily, participating in hobbies or community events, or simply being fully\npresent in everyday activities like walking outdoors or meditating.\n\nRemember to take it one step at a time and be patient with yourself as you work\nthrough these feelings. You can also try to create a self-care plan that\nincludes regular exercise, proper nutrition, and sufficient sleep. Taking care\nof your physical well-being can help improve your overall sense of connection\nand well-being.\n\nHere's a checklist for you to consider incorporating into your daily routine:\n1. Physical activity (30 minutes or more)\n2. Balanced diet with a variety of fruits, vegetables, lean proteins, and whole\ngrains\n3. Adequate sleep (7-9 hours)\n4. Time to unwind and engage in activities you enjoy\n5. Limiting screen time before bed\n6. Keeping a gratitude journal to focus on positive aspects of your life\n7. Connect with others through phone calls, video chats, or in-person\ninteractions\n8. Setting achievable goals and celebrating small successes\n\nRemember, Samantha is here for you, and I'm always ready to help. Don't\nhesitate to reach out if you need support or want to discuss any concerns.\nTogether, we can work on creating a more fulfilling life for you.\nSince you’re running the model locally (for yourself), I would recommend trying out “uncensored” models which don’t have any filters. You can try llama2-uncensored, mistral-instruct and zephyr.\nIf you’re exposing the model to the internet, I would suggest using one of the “aligned” models. Orca-Mini-v3 is a good choice."
  },
  {
    "objectID": "posts/17-ollama.html#performance",
    "href": "posts/17-ollama.html#performance",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "Performance",
    "text": "Performance\nYou can /set verbose to enable verbose mode. It will show you the performance metrics like this at the end of each response:\ntotal duration:       37.064346833s\nload duration:        15.515833ms\nprompt eval count:    1394 token(s)\nprompt eval duration: 17.515358s\nprompt eval rate:     79.59 tokens/s\neval count:           199 token(s)\neval duration:        18.932322s\neval rate:            10.51 tokens/s\n\nFor a 7B default model for samantha-mistral, I get ~10 tokens/sec in Mac M1 air(8GB RAM).\nFor the same model, I get around ~28 tokens/sec in Mac M1 Pro(16GB RAM)."
  },
  {
    "objectID": "posts/17-ollama.html#create-custom-models",
    "href": "posts/17-ollama.html#create-custom-models",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "Create custom models",
    "text": "Create custom models\nYou can also create your own custom models from any GGUF model. You can use the ollama create for that.\nHere’s an example:\nI wanted to play with tinyllama, a 1.1B parameter model.\nFirst, I downloaded it on my local machine.\nThen, I created a modelfile like this:\nFROM models/tinyllama-1.1b-chat-v0.3.Q6_K.gguf\nPARAMETER temperature 0.7\nPARAMETER stop \"&lt;|im_start|&gt;\"\nPARAMETER stop \"&lt;|im_end|&gt;\"\nTEMPLATE \"\"\"\n&lt;|im_start|&gt;system\n{{ .System }}&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\n{{ .Prompt }}&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n\"\"\"\nSYSTEM \"\"\"You are a helpful assistant.\"\"\"\nNext, I ran the following command to create a custom model:\nollama create saikatkumardey/tinyllama:latest -f modelfile\nI pushed the model to ollama.ai registry. You can find it here.\nTo use the model now, simply run:\nollama run saikatkumardey/tinyllama:latest"
  },
  {
    "objectID": "posts/17-ollama.html#how-to-access-ollama-from-langchain",
    "href": "posts/17-ollama.html#how-to-access-ollama-from-langchain",
    "title": "How to Run Large Language Models on Your Laptop with Ollama.ai",
    "section": "How to access Ollama from Langchain?",
    "text": "How to access Ollama from Langchain?\n\nInitialise\nfrom langchain.chat_models import ChatOllama\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\nchat_model = ChatOllama(model=\"samantha-mistral\",\n                        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n\n\nChat\n\nfrom langchain.schema import HumanMessage\nmessages = []\n\nwhile user_message := input(\"\\n&gt;&gt;&gt; \"):\n    if user_message == \"/quit\":\n        break\n    messages.append(HumanMessage(content=user_message))\n    ai_message = chat_model(messages)\n    messages.append(ai_message)"
  },
  {
    "objectID": "posts/14-love-what-you-do.html",
    "href": "posts/14-love-what-you-do.html",
    "title": "How to love what you do",
    "section": "",
    "text": "Finding the work you love can often seem like a daunting task, but there’s no secret ingredient to it. Instead, the key is to simply start producing. Whether you’re a writer, an artist, a musician, or anything else, the most important thing is to just get started and begin creating.\nAt first, it’s okay to focus on quantity rather than quality. Don’t worry about making everything perfect from the beginning – just keep producing and putting yourself out there. As you continue to create, you will naturally start to get better at it. And as you improve, you will begin to find more and more enjoyment in the work itself.\nIt’s important to remember that finding the work you love isn’t something that happens overnight. It takes time and effort to develop your skills and find your passion. But by simply starting to produce and focusing on improving, you will gradually start to love the work you’re doing.\nSo don’t worry about trying to find that elusive secret ingredient – just start creating and let the love for your work develop naturally over time. Keep producing, keep improving, and eventually you will find the work that truly brings you joy and fulfillment."
  },
  {
    "objectID": "posts/1-keep-investing.html",
    "href": "posts/1-keep-investing.html",
    "title": "The Power of Consistent Investing",
    "section": "",
    "text": "If you have money to spare, it’s always a good idea to invest it. Investing can help your money grow and provide financial security for the future. But where should you invest your money? And how can you make the most of your investments? Here are some key tips to keep in mind.\nFirst and foremost, don’t try to pick individual stocks. Unless you have a lot of experience and expertise in the stock market, it’s generally not a good idea to try and pick individual stocks. Instead, invest in index funds and ETFs. These types of investments are more diversified, which means they can help reduce the overall risk of your investment portfolio. And as the saying goes, “don’t put all your eggs in one basket.”\nAnother important tip is to automate your investments. One of the best ways to do this is through a systematic investment plan (SIP). A SIP allows you to automatically invest a fixed amount of money at regular intervals. This can help you build a consistent investment strategy and take the emotion out of investing. Plus, it can be a convenient way to make sure you’re always investing, even when you’re busy with other things.\nIt’s also important to remember that time in the market is more important than timing the market. In other words, it’s not about trying to predict when the market will go up or down. Instead, focus on building a long-term investment strategy that can help your money grow over time. And remember, the real fruit of your investments will be seen years later. So don’t be discouraged if you don’t see immediate results. Let compound interest do its thing and your investments can grow significantly over time.\nFinally, don’t worry too much about the market. It’s natural to want to stay up-to-date on the latest market news and trends. But ultimately, your time is better spent focusing on being the best at what you do. And remember, when the market is down, it’s actually an opportunity to buy equity at a discount. So don’t let market fluctuations discourage you. Keep investing consistently and let your money grow over time."
  },
  {
    "objectID": "posts/6-accuracy-is-a-poor-error-metric.html",
    "href": "posts/6-accuracy-is-a-poor-error-metric.html",
    "title": "Accuracy Is a Poor evaluation Metric",
    "section": "",
    "text": "For classification problems, something like Cross-entropy is a good metric for minimizing your model’s loss. However, we need something easier to convey to the stakeholders. Accuracy is a very easy way to show our model performances. The caveat? Accuracy would be misleading for imbalanced classes.\nHere’s why.\nLet’s say that you’ve built a model for detecting cancer. Here’s how the confusion matrix would look like for a dataset on cancer cases.\n\n\n\n\nPredicted Cancer\nPredicted cancer-free\n\n\n\n\nActual cancer cases\n10 (TP)\n5 (FN)\n\n\nActual cancer-free cases\n150 (FP)\n800 (TN)\n\n\n\nThe dataset has 950 cancer-free patients and 15 patients with cancer. The accuracy of the model = fraction of correct predictions = (10 + 800) / (10 + 5 + 150 + 800) = 0.84.\nWell, the cancer cases are quite rare, so it barely has any effect on the accuracy.\nIf the model had predicted every case as cancer-free, the confusion matrix would look like the following:\n\n\n\n\nPredicted Cancer\nPredicted cancer-free\n\n\n\n\nActual cancer cases\n0 (TP)\n15 (FN)\n\n\nActual cancer-free cases\n0 (FP)\n950 (TN)\n\n\n\nAccuracy = 950/(950 + 15) = 0.984%.\nThat is not what we want to report to our stakeholders.\nWhat are our options?\nIn such cases with class imbalance, we usually look at precision and recall.\nPrecision\nprecision = TP/(TP + FP)\nPrecision is out of all the cancer diagnosis made by the model, how many of them actually have cancer. In the first case, model predicted 165 cases as having cancer but only 15 of them actually had cancer. So, the precision is 15/165 which is quite low!\nRecall\nrecall = TP/(TP+FN)\nRecall is out of all the actual cancer cases, how many could the model detect? In the first case, model detected 15 out of 20 cancer cases. So, the recall is 15/20 = 0.75. That’s not bad!\nOur objective is to detect as many cancer cases as we can (TP) while minimizing the false diagnosis of cancer (FP). In other words, we want to have high recall with high precision.\nAll of these metrics rely on the probability threshold chosen to classify each sample as having cancer or not. If prediction probability &gt; threshold, predict cancer.\nFor example, if you choose 0.9 as the threshold, you might only classify cases where the model is highly confident ie, high precision. However, you might miss out on many cases at that threshold ie, low recall. Instead, if you keep 0.1 as the threshold, you might capture all the cancer cases but you’d be scaring a lot of other cancer-free patients with misdiagnosis as well.\nBy varying the probability threshold, you could check the trade-off between precision & recall, also called the precision-recall curve.\nSometimes, precision & recall are combined together into one metric, called F1 score.\nF1 = 2 / (1/precision + 1/recall)\nThere’s another variant of the precision-recall curve which is agnostic to the probability threshold selected. It’s called the ROC curve (Receiver Operating Characteristics). The area under the curve (AUC) is demonstrative of the overall model performance. AUC is useful to know how well the model is in classifying both the classes.\nConclusion\n\nDo not use accuracy metric when there’s a class imbalance.\nUse F1 or ROC-AUC instead.\n\n\nReference\n\nPractical Machine Learning for Computer Vision\nPrecision Recall\nROC Curve"
  },
  {
    "objectID": "posts/18-snapsort.html",
    "href": "posts/18-snapsort.html",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "",
    "text": "I wanted a simple tool to segregate screenshots, prescriptions and other document images on my laptop. I couldn’t find any tool that could do this locally, so I decided to build one myself. I used OpenAI’s CLIP model to build this tool. I call it SnapSort. You can find it here."
  },
  {
    "objectID": "posts/18-snapsort.html#what-is-snapsort",
    "href": "posts/18-snapsort.html#what-is-snapsort",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "What is SnapSort?",
    "text": "What is SnapSort?\nSnapSort is a CLI tool that uses OpenAI’s CLIP model to sort your photos locally. It can be used to sort photos into categories such as screenshots, documents, memes, etc. It can also be used to sort photos into custom categories."
  },
  {
    "objectID": "posts/18-snapsort.html#how-does-snapsort-work",
    "href": "posts/18-snapsort.html#how-does-snapsort-work",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "How does SnapSort work?",
    "text": "How does SnapSort work?\nSnapSort uses OpenAI’s CLIP model to perform zero-shot prediction from a handful of labels/categories provided to it. It then sorts the photos into the categories based on the predictions. We use HuggingFace’s CLIP model here.\nFor my use-case, I provided the following categories to SnapSort, along with a batch of images from the disk:\n[\n  \"a screenshot of a software interface or a screen capture from phone\",\n  \"a photo of an invoice or a receipt\",\n  \"a photo of a real-world scene, an object, a person, or any image not fitting the description of a screenshot, receipt, or invoice\"\n]\nCLIP is used to generate the a text-image similarity score for each category. An image is then assigned to the category with the highest score. We could set a threshold for the score to assign an image to a category only if the score is above the threshold."
  },
  {
    "objectID": "posts/18-snapsort.html#how-to-use-snapsort",
    "href": "posts/18-snapsort.html#how-to-use-snapsort",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "How to use SnapSort?",
    "text": "How to use SnapSort?\n\ngit clone git@github.com:saikatkumardey/snapsort.git\npoetry shell\npoetry install\npython snapsort.py dir --dry-run (dry-run to see the results without actually moving the files)\n\nYou should run python snapsort.py --help to see the available options."
  },
  {
    "objectID": "posts/18-snapsort.html#whats-next",
    "href": "posts/18-snapsort.html#whats-next",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "What’s next?",
    "text": "What’s next?\nSnapSort also inherits the limitations of CLIP.\n\nWe need to manually define the categories in a specific format for CLIP like “a photo of {object}”. Sometimes, we don’t know all the categories beforehand. We would ideally like it to be automatically categorised and segregated for us. We could use CLIP+GPT2 or Llava to describe each image. Then we could cluster the images into different categories based on the descriptions.\nNegative label is a must. Since all CLIP does is provide a similarity score between a text and an image, we need to provide a negative label as well. We need a catch-all category for images that don’t fit into any of the categories right now, so we don’t move them into any of the categories.\nCLIP is not perfect. It can sometimes misclassify images. We would ideally like to have a way to correct the misclassifications. If we have a very specific use-case like mine, we could train a logistic regression model on top of CLIP to have a better classifications."
  },
  {
    "objectID": "posts/18-snapsort.html#concluding-thoughts",
    "href": "posts/18-snapsort.html#concluding-thoughts",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "Concluding thoughts",
    "text": "Concluding thoughts\nCLIP is a very powerful model. I have been wanting to use it for a while now. I barely scratched the surface of what CLIP can do. I am excited to see what else I can do with it."
  },
  {
    "objectID": "posts/18-snapsort.html#references",
    "href": "posts/18-snapsort.html#references",
    "title": "SnapSort - Sorting your photos locally using OpenAI’s CLIP model",
    "section": "References",
    "text": "References\n\nSnapSort\nOpenAI’s Repo on CLIP\n🤗"
  },
  {
    "objectID": "posts/2-relax.html",
    "href": "posts/2-relax.html",
    "title": "The Importance of Focusing on One Thing at a Time",
    "section": "",
    "text": "When it feels like the world is pulling us in a million different directions, it can be easy to become overwhelmed and stressed. We may feel like we need to multitask and tackle everything at once, but this can often be counterproductive. Instead, it’s important to take a step back and focus on one thing at a time.\nThere’s a common misconception that multitasking is a sign of productivity. In reality, multitasking can actually decrease our productivity and make it more difficult for us to complete tasks effectively. When we try to do too many things at once, our brains become overwhelmed and we end up doing a mediocre job on each task.\nOn the other hand, focusing on one thing at a time allows us to concentrate and give our full attention to the task at hand. This allows us to complete tasks more efficiently and with a higher level of quality.\nIn addition to increasing our productivity, focusing on one thing at a time also has the added benefit of bringing us inner peace. When we’re constantly multitasking and trying to do a million things at once, we can become anxious and stressed. By focusing on one thing at a time, we can let go of that stress and find a sense of calm and clarity.\nSo next time you’re feeling pulled in a million different directions, take a step back and breathe. Instead of trying to multitask, focus on one thing at a time and delegate the rest. Not only will this increase your productivity, but it will also bring you inner peace. Remember, nothing is more important than taking care of yourself and finding inner peace."
  },
  {
    "objectID": "posts/11-focal-loss.html",
    "href": "posts/11-focal-loss.html",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "",
    "text": "Class imbalance occurs when the number of observations in one or more classes is significantly different from the number of observations in other classes. This can lead to poor model performance, particularly when the minority class is important to predict accurately.\nFocal loss is a loss function that down-weights the contribution of well-classified examples and focuses on hard-to-classify examples. This can help to improve the performance of a machine learning model when dealing with class imbalance.\nIn this post, we will understand the concept of focal loss and how it can be implemented in a machine learning model. We will also compare its effectiveness to other methods for solving class imbalance."
  },
  {
    "objectID": "posts/11-focal-loss.html#focal-loss",
    "href": "posts/11-focal-loss.html#focal-loss",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Focal loss",
    "text": "Focal loss\nFocal loss is a variant of the cross-entropy loss function that is specifically designed to address class imbalance. It is defined as:\nFL(p) = -alpha * (1-p)^gamma * log(p)\nwhere\n\np is the predicted probability of the correct class\nalpha is a weighting factor for each sample,\ngamma is a tunable focusing parameter.\n\nThe focal loss function has the effect of down-weighting well-classified examples, and up-weighting examples that are misclassified. This can be useful in class imbalance scenarios, where the model may be inclined to simply predict the majority class for all examples in order to achieve a high overall accuracy. By using focal loss, the model is encouraged to focus on the hard examples, and to learn to predict the minority class more accurately."
  },
  {
    "objectID": "posts/11-focal-loss.html#focal-loss-parameters---alpha-and-gamma",
    "href": "posts/11-focal-loss.html#focal-loss-parameters---alpha-and-gamma",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Focal loss parameters - alpha and gamma",
    "text": "Focal loss parameters - alpha and gamma\nIn the focal loss formula, alpha and gamma are two tunable parameters that control the behavior of the loss function.\nalpha is a weighting factor that is applied to each sample in the batch. It has the effect of down-weighting well-classified examples and up-weighting examples that are misclassified. The value of alpha is typically set such that the majority class has a lower weighting than the minority class, to help the model focus on the hard examples.\ngamma is a focusing parameter that controls the degree to which the loss is down-weighted for well-classified examples. The value of gamma is typically set to a value greater than 1, which has the effect of down-weighting the loss for well-classified examples more heavily. This can help the model to focus on the hard examples and to learn to predict the minority class more accurately."
  },
  {
    "objectID": "posts/11-focal-loss.html#code-sample",
    "href": "posts/11-focal-loss.html#code-sample",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Code sample",
    "text": "Code sample\nHere is an example of focal loss implemented in PyTorch:\nimport torch\ndef focal_loss(logits, targets, alpha, gamma):\n    probs = torch.sigmoid(logits)\n    weights = alpha * (1 - probs) ** gamma\n    focal_loss = -weights * torch.log(probs)\n    return focal_loss.mean()\nThis function takes the model’s predicted logits, the true targets, and the values of alpha and gamma as input and returns the average focal loss. It can then be used in the training loop of a machine learning model as follows:\n# Train the model\nfor inputs, targets in train_loader:\n    # Calculate predicted logits\n    logits = model(inputs)\n\n    # Calculate focal loss\n    loss = focal_loss(logits, targets, alpha=0.25, gamma=2.0)\n\n    # Backpropagate and update the model weights\n    loss.backward()\n    optimizer.step()\nIn this example, we use the focal loss function to calculate the loss for each batch of training data and update the model weights using backpropagation. The values of alpha and gamma can be adjusted as needed to achieve the best performance."
  },
  {
    "objectID": "posts/11-focal-loss.html#thoughts-on-parameter-tuning",
    "href": "posts/11-focal-loss.html#thoughts-on-parameter-tuning",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Thoughts on parameter tuning",
    "text": "Thoughts on parameter tuning\nIn the example above, the focal loss function is defined as a partial function, with alpha and gamma as fixed parameters. The model is trained using the Adam optimizer, and the focal loss is used as the criterion. By adjusting the values of alpha and gamma, you can tune the focal loss function to suit your specific dataset and task.\nThe values of alpha and gamma can be tuned to suit the specific dataset and task. In our example, we used alpha=0.75 and gamma=2.0, but these values may not be optimal for all datasets. By experimenting with different values of these parameters, you can find the settings that produce the best results for your model.\nFor example, if you increase the value of alpha, the weighting of the majority class will be decreased, and the weighting of the minority class will be increased. This can help the model to focus more on the minority class, and to learn to predict it more accurately. Similarly, if you increase the value of gamma, the down-weighting of well-classified examples will be increased, which can also help the model to focus more on the hard examples."
  },
  {
    "objectID": "posts/11-focal-loss.html#example",
    "href": "posts/11-focal-loss.html#example",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Example",
    "text": "Example\nIn this example, we will demonstrate the effectiveness of focal loss for solving class imbalance in a machine learning model. We will use a real-world example of a binary classification problem to illustrate how focal loss can improve the performance of a model on an imbalanced dataset.\nClass imbalance is a common problem in medical imaging applications where the number of positive examples (e.g. diseased images) is often much smaller than the number of negative examples (e.g. healthy images). In this case study, we will consider a dataset of medical images and a binary classification task of predicting whether an image is healthy or diseased. The dataset is imbalanced, with a large number of healthy images and a small number of diseased images.\nTo start, we will train a convolutional neural network (CNN) using the cross-entropy loss as the training loss. This loss function is commonly used in classification tasks, as it measures the difference between the predicted probabilities and the true labels. However, it has the disadvantage of treating all classes equally, which can result in poor performance on imbalanced datasets.\n\n\n\n\n\n\n\n\n\n\n\nImage\nTrue Label\nHealthy\nDiseased\nCross-Entropy Loss\nFocal Loss\n\n\n\n\n1\nHealthy\n0.8\n0.2\n0.2231435\n0.0436035\n\n\n2\nHealthy\n0.9\n0.1\n0.1053605\n0.0160707\n\n\n3\nHealthy\n0.7\n0.3\n0.3566749\n0.0479158\n\n\n4\nHealthy\n0.6\n0.4\n0.5150763\n0.0687455\n\n\n5\nDiseased\n0.1\n0.9\n0.1053605\n0.8\n\n\n\nAs we can see, the focal loss for the diseased image is significantly higher than the loss for the healthy images. This is because the focal loss down-weights the contribution of well-classified examples and focuses on hard-to-classify examples. In this case, the healthy images are well-classified and have a low focal loss, while the diseased image is hard-to-classify and has a high focal loss. This helps the model to better learn the patterns in the minority class of diseased images."
  },
  {
    "objectID": "posts/11-focal-loss.html#conclusion",
    "href": "posts/11-focal-loss.html#conclusion",
    "title": "Solving Class Imbalance with Focal Loss",
    "section": "Conclusion",
    "text": "Conclusion\nIn this blog post, we explored the problem of class imbalance in machine learning and introduced focal loss as a potential solution. We discussed the motivations behind focal loss and provided an example of how to implement it in a machine learning model. We also compared focal loss to other methods for solving class imbalance, such as undersampling and oversampling. Finally, we provided a case study of using focal loss to improve the performance of a machine learning model with class imbalance.\nOverall, focal loss is an effective technique for addressing class imbalance in machine learning. It can improve the performance of models by weighting the loss function to focus on hard-to-classify examples, while still allowing easy examples to contribute to the learning process.\nIf you’re interested in learning more about focal loss and other methods for solving class imbalance, there are many resources available online. Some suggested readings include:\n\nFocal Loss for Dense Object Detection\nFocal Loss\nA Beginner’s Guide To Focal Loss In Object Detection"
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "",
    "text": "homescreen\n\n\nI recently (re)read Atomic Habits by James Clear which highlights how small, consistent habits can lead to remarkable results over time. The book motivated me to be more intentional about building good habits into my routines.\nI looked around at existing habit tracking apps on the App Store but couldn’t find one that was simple and minimalistic enough for my needs. Many were bloated with unnecessary gamification, social sharing, subscriptions, etc.\nSo I decided to build a custom habit tracking app tailored exactly to my requirements:\n\nTrack basic habit data like streaks\nSimple and clean interface\nFast and performant\nWork offline without internet\nStore data locally on device\n\nIn addition, I wanted to learn iOS development with SwiftUI. Building this app would allow me to gain practical skills in:\n\nDeclarative UI development with SwiftUI\nManaging state and data flow\nPersisting data locally\nWorking with mobile platform APIs like notifications\n\nTo see the habit tracker app in action, check out this demo and the source code on GitHub.\nIn this post, I’ll share how I built this habit tracking app from idea to working product using SwiftUI and other key iOS frameworks."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#introduction",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#introduction",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "",
    "text": "homescreen\n\n\nI recently (re)read Atomic Habits by James Clear which highlights how small, consistent habits can lead to remarkable results over time. The book motivated me to be more intentional about building good habits into my routines.\nI looked around at existing habit tracking apps on the App Store but couldn’t find one that was simple and minimalistic enough for my needs. Many were bloated with unnecessary gamification, social sharing, subscriptions, etc.\nSo I decided to build a custom habit tracking app tailored exactly to my requirements:\n\nTrack basic habit data like streaks\nSimple and clean interface\nFast and performant\nWork offline without internet\nStore data locally on device\n\nIn addition, I wanted to learn iOS development with SwiftUI. Building this app would allow me to gain practical skills in:\n\nDeclarative UI development with SwiftUI\nManaging state and data flow\nPersisting data locally\nWorking with mobile platform APIs like notifications\n\nTo see the habit tracker app in action, check out this demo and the source code on GitHub.\nIn this post, I’ll share how I built this habit tracking app from idea to working product using SwiftUI and other key iOS frameworks."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#project-setup",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#project-setup",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Project Setup",
    "text": "Project Setup\nI started by creating a new Xcode project using the SwiftUI App template. This gave me a ContentView SwiftUI file and basic app scaffolding to build on top of.\nI used a TabView to divide the app into two main tabs - Current Habits and Completed Habits:\nTabView {\n\n  NavigationView {\n    CurrentHabitsView()\n  }\n  .tabItem {\n    Label(\"Current\", systemImage: \"list.bullet\")\n  }\n\n  NavigationView {\n    CompletedHabitsView()\n  }\n  .tabItem {\n   Label(\"Completed\", systemImage: \"checkmark\")\n  }\n\n}\n\n\nTabView renders each view in its own tab. The .tabItem modifier configures the navigation tab bar item for that view.\nI added NavigationView wrappers to each screen so I could easily add navigation bars later.\nFor the Current Habits page, I displayed the list of habits using a SwiftUI List:\nList {\n  ForEach(habits) { habit in\n    HabitRow(habit: habit)\n  }\n}\nThe List displays rows dynamically based on the habits array. ForEach loops through each habit to configure the view for that row.\nThis declarative paradigm makes it really easy to render views from data."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#state-management",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#state-management",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "State Management",
    "text": "State Management\nI used SwiftUI’s ObservableObject protocol to manage state across my app.\nI created a HabitStore class to hold my array of habits:\nclass HabitStore: ObservableObject {\n\n  @Published var habits = [Habit]()\n\n}\nThe @Published property wrapper means any view observing the store will update when the habits array changes.\nI can pass the store into views using the .environmentObject modifier:\nCurrentHabitsView()\n  .environmentObject(HabitStore())\nThen access it from a child view:\n@EnvironmentObject var store: HabitStore\n\nlet habits = store.habits\nThis observer pattern allows decoupling - the store doesn’t know about the views using it.\nViews simply observe for changes and refresh accordingly. This made managing state much easier."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#modeling-habits",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#modeling-habits",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Modeling Habits",
    "text": "Modeling Habits\n\nI created a Habit class to model each habit:\nclass Habit: Identifiable {\n\n  var id: UUID\n  var title: String\n  var completedDates: [Date]\n\n}\nConforming to Identifiable means SwiftUI can uniquely identify instances.\nThis class encapsulates all the data and behavior for a single habit:\nfunc calculateStreak() -&gt; Int {\n  // Logic to calculate current streak\n}\n\nfunc isCompleted(on date: Date) -&gt; Bool {\n  // Check if completed on given date\n}\nGrouping this related logic makes the app more maintainable as it grows.\nMy HabitStore class acts as the main data store, holding the array of habits:\nclass HabitStore {\n\n  @Published var habits = [Habit]()\n\n}\nPublished means any views observing the store will update when the habits array changes.\nBy abstracting raw habit data into a domain model, I can manipulate and query habits directly through the Habit API. This provides more flexibility than working directly with arrays and dictionaries.\nFor example, marking a habit completed just involves:\nhabitStore.complete(habit)\nWithout needing direct array manipulation."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#data-persistence",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#data-persistence",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Data Persistence",
    "text": "Data Persistence\nI wanted to persist habits between app launches without needing a database.\nFor simple data storage, I used UserDefaults:\nextension UserDefaults {\n\n  func saveHabits(_ habits: [Habit]) {\n    // Encode habits\n  }\n\n  func loadHabits() -&gt; [Habit] {\n    // Decode habits\n  }\n}\nUserDefaults stores key-value data, perfect for persisting small pieces of data like user preferences and app state.\nMy HabitStore handles loading and saving to UserDefaults:\nclass HabitStore {\n\n  func loadHabits() {\n    self.habits = UserDefaults.loadHabits()\n  }\n\n  func saveHabits() {\n    UserDefaults.saveHabits(habits)\n  }\n\n}\nThis kept my data persistence simple while still allowing habits to be stored across launches.\nFor more complex data, I’d need a database. But for this basic habit data, UserDefaults provided an easy solution without that overhead."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#handling-user-input",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#handling-user-input",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Handling User Input",
    "text": "Handling User Input\n\nTo allow editing habits, the Add/Edit Habit views use @Binding:\nstruct AddHabit {\n\n  @Binding var title: String\n  @Binding var startDate: Date\n\n}\n@Binding creates a two-way binding to the source of truth for those properties. Updating the binding also updates the source.\nWhen creating the view, I pass bindings to the properties I want editable:\nAddHabit(title: $newHabit.title, startDate: $newHabit.startDate)\nThis avoids needing to pass callback closures up and down the view hierarchy.\nFor completing habits, I update the store:\nfunc complete(_ habit: Habit) {\n\n  habit.completed = true\n  habitStore.update(habit)\n\n}\nThanks to ObservableObject, any views observing the store automatically update on changes.\nI also used swipe actions for quick completion:\n.swipeActions {\n\n  Button(action: {\n    store.complete(habit)\n  })\n\n}\nMaking it easy to handle user input like tapping rows or swiping."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#local-notifications",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#local-notifications",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Local Notifications",
    "text": "Local Notifications\n\nFor habit reminders, I used the UserNotifications framework to schedule local notifications.\nFirst I request notification authorization:\nUNUserNotificationCenter.current().requestAuthorization(options: [.alert, .sound]) { granted, _ in\n\n  if granted {\n    // Scheduling code\n  }\n\n}\nThen to schedule a notification:\nlet content = UNMutableNotificationContent()\ncontent.title = \"Habit Reminder\"\n\nlet trigger = UNTimeIntervalNotificationTrigger(...)\n\nlet request = UNNotificationRequest(identifier: ..., content: content, trigger: trigger)\n\nUNUserNotificationCenter.current().add(request)\nWhen a notification is tapped, I can update the habit as completed:\nfunc userNotificationCenter(_ center: UNUserNotificationCenter, didReceive response: UNNotificationResponse) {\n\n  let habit = Habit(id: response.notification.request.identifier)\n  habitStore.complete(habit)\n\n}\nThe notification request identifier maps to the habit ID to update.\nThis allows me to build a reminders system using local notifications and update app state when a notification is received."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#future-enhancements",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#future-enhancements",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Future Enhancements",
    "text": "Future Enhancements\nWhile I’m happy with this initial habit tracker, there are a few minimal enhancements I have in mind:\n\nProgress bars to visualize habit completion rates\nSorting and tagging habits\nAdding simple notes to habit entries\nData export\nShare habit calendar grid"
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#conclusion",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#conclusion",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Conclusion",
    "text": "Conclusion\nBuilding this habit tracking app with SwiftUI was a great learning experience. Here are some key takeaways:\n\nSwiftUI’s declarative syntax made building UI fast and intuitive. Describing views rather than imperatively constructing them took some adjusting, but proved powerful.\nObservableObject, @Published, and @EnvironmentObject provided a clean pattern for state management. By abstracting state into a store, I avoided tight coupling between views.\nUserDefaults offered a simple persistence solution without needing a database. For more complex data, Core Data or SQLite could be used.\nThe UserNotifications framework enabled scheduling reminders as local notifications. Integrating with system APIs like notifications was really handy.\nMVVM architecture with nicely encapsulated View, ViewModel, and Model layers kept the app maintainable as it grows.\n\nWhile basic, this app gave me exposure to real mobile development concepts I would encounter in any professional iOS app."
  },
  {
    "objectID": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#try-the-app",
    "href": "posts/ios-app/15-minimalist-habit-tracking-ios-app.html#try-the-app",
    "title": "Minimalist iOS Habit Tracking App",
    "section": "Try the App",
    "text": "Try the App\nI’d love for others to be able to use this habit tracking app and provide feedback.\n\nIt’s open source, so feel free to check out the code on GitHub for the final habit tracker app."
  },
  {
    "objectID": "posts/19-mobilenets/19-mobilenet-v1.html",
    "href": "posts/19-mobilenets/19-mobilenet-v1.html",
    "title": "Why are mobilenets so fast?",
    "section": "",
    "text": "Mobile devices have become ubiquitous in our daily lives, enabling us to capture, process, and share visual information anytime and anywhere. However, running state-of-the-art computer vision models on mobile devices poses significant challenges, such as limited computational resources, battery life, and network bandwidth. Therefore, there is a need for efficient and compact models that can perform well on mobile and embedded vision applications.\nMobilenets are a family of neural networks that are designed to address these challenges. They are based on a novel architecture that uses depth-wise separable convolutions, which reduce the number of parameters and computations compared to standard convolutions. They also use width and resolution multipliers, which allow for fine-grained control over the network size and accuracy trade-off. Mobilenets can achieve comparable or even superior performance to larger and more complex models on various vision tasks, such as image classification, object detection, face recognition, and more.\nIn this blog post, we will explain the main ideas behind mobilenet-v1 and how they achieve high efficiency and accuracy."
  },
  {
    "objectID": "posts/19-mobilenets/19-mobilenet-v1.html#depth-wise-separable-convolutions",
    "href": "posts/19-mobilenets/19-mobilenet-v1.html#depth-wise-separable-convolutions",
    "title": "Why are mobilenets so fast?",
    "section": "Depth-wise separable convolutions",
    "text": "Depth-wise separable convolutions\nDepth-wise separable convolutions are the core building blocks of mobilenets. They are a variant of standard convolutions that decompose the convolution operation into two steps: depth-wise and point-wise.\nA standard convolution applies a set of filters to the input feature map, producing an output feature map. Each filter has the same spatial dimensions as the input, but a different number of channels. The filter slides over the input, performing element-wise multiplication and summation at each position, and generating a scalar output. The output feature map has the same spatial dimensions as the input, but a different number of channels, depending on the number of filters.\nA depth-wise convolution applies a single filter per input channel, producing an intermediate feature map. The filter has the same spatial dimensions as the input, but only one channel. The filter slides over the input, performing element-wise multiplication and summation at each position, and generating a scalar output. The intermediate feature map has the same spatial dimensions and number of channels as the input.\nA point-wise convolution applies a set of filters to the intermediate feature map, producing an output feature map. Each filter has a spatial dimension of 1x1, but a different number of channels. The filter slides over the intermediate feature map, performing element-wise multiplication and summation at each position, and generating a scalar output. The output feature map has the same spatial dimensions as the intermediate feature map, but a different number of channels, depending on the number of filters.\n\n\n\nStandard vs depthwise separable convolutions\n\n\nThe main advantage of depth-wise separable convolutions is that they reduce the number of parameters and computations compared to standard convolutions. This is because the depth-wise convolution only applies one filter per input channel, and the point-wise convolution only applies one filter per intermediate channel. The number of parameters and computations for a standard convolution is given by:\n\\[\nP_s = K \\times K \\times C_i \\times C_o\n\\]\n\\[\nC_s = H \\times W \\times K \\times K \\times C_i \\times C_o\n\\]\nwhere\n\n\\(K\\) is the filter size,\n\\(C_i\\) is the number of input channels,\n\\(C_o\\) is the number of output channels\n\\(H\\) is the input height\n\\(W\\) is the input width.\n\nThe number of parameters and computations for a depth-wise separable convolution is given by:\n\\[\nP_d = K \\times K \\times C_i + C_i \\times C_o\n\\]\n\\[\nC_d = H \\times W \\times K \\times K \\times C_i + H \\times W \\times C_i \\times C_o\n\\]\nThe ratio of the number of parameters and computations for a standard convolution to a depth-wise separable convolution is given by:\n\\[\n\\frac{P_s}{P_d} = \\frac{K \\times K \\times C_i \\times C_o}{K \\times K \\times C_i + C_i \\times C_o} \\approx \\frac{C_o}{1 + \\frac{1}{K^2}}\n\\]\n\\[\n\\frac{C_s}{C_d} = \\frac{H \\times W \\times K \\times K \\times C_i \\times C_o}{H \\times W \\times K \\times K \\times C_i + H \\times W \\times C_i \\times C_o} \\approx \\frac{C_o}{1 + \\frac{1}{K^2}}\n\\]\nAs we can see, the ratio depends on the filter size and the number of output channels. For a typical filter size of 3x3 and a large number of output channels, depth-wise separable convolutions can reduce the number of parameters and computations by ~10x."
  },
  {
    "objectID": "posts/19-mobilenets/19-mobilenet-v1.html#width-and-resolution-multipliers",
    "href": "posts/19-mobilenets/19-mobilenet-v1.html#width-and-resolution-multipliers",
    "title": "Why are mobilenets so fast?",
    "section": "Width and resolution multipliers",
    "text": "Width and resolution multipliers\nWidth and resolution multipliers are two global hyperparameters that mobilenets use to control the width and resolution of the network. They allow for fine-grained trade-off between network size, accuracy, and resource consumption.\nThe width multiplier, denoted by \\(\\alpha\\), is used to adjust the number of filters in each layer. It is applied uniformly to all layers, except the first and the last ones. The number of filters in layer \\(l\\) is given by:\n\\[\nF_l = \\alpha \\times F_l^0\n\\]\nwhere \\(F_l^0\\) is the original number of filters in layer \\(l\\). The value of \\(\\alpha\\) is typically chosen from the set \\(\\{1, 0.75, 0.5, 0.25\\}\\), where \\(\\alpha = 1\\) corresponds to the original network, and smaller values of \\(\\alpha\\) correspond to thinner networks. The effect of the width multiplier on the number of parameters and computations is given by:\n\\[\nP_\\alpha = \\alpha^2 \\times P_1\n\\]\n\\[\nC_\\alpha = \\alpha^2 \\times C_1\n\\]\nwhere \\(P_1\\) and \\(C_1\\) are the number of parameters and computations for the original network (\\(\\alpha = 1\\)). As we can see, the width multiplier reduces the number of parameters and computations quadratically.\nThe resolution multiplier, denoted by \\(\\beta\\), is used to adjust the input size of the network. It is applied uniformly to all layers, except the first and the last ones. The input size of layer \\(l\\) is given by:\n\\[\nS_l = \\beta \\times S_l^0\n\\]\nwhere \\(S_l^0\\) is the original input size of layer \\(l\\). The value of \\(\\beta\\) is typically chosen from the set \\(\\{1, 0.75, 0.5, 0.25\\}\\), where \\(\\beta = 1\\) corresponds to the original network, and smaller values of \\(\\beta\\) correspond to lower resolution networks. The effect of the resolution multiplier on the number of parameters and computations is given by:\n\\[\nP_\\beta = P_1\n\\]\n\\[\nC_\\beta = \\beta^2 \\times C_1\n\\]\nwhere \\(P_1\\) and \\(C_1\\) are the number of parameters and computations for the original network (\\(\\beta = 1\\)). As we can see, the resolution multiplier does not affect the number of parameters, but reduces the number of computations quadratically.\nThe optimal values of \\(\\alpha\\) and \\(\\beta\\) depend on the resource constraints and accuracy requirements of the application. For example, if the application requires high accuracy and has sufficient resources, then \\(\\alpha = 1\\) and \\(\\beta = 1\\) would be the best choice. However, if the application requires low latency and has limited resources, then smaller values of \\(\\alpha\\) and \\(\\beta\\) would be more suitable."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html",
    "href": "posts/13-leetcode-patterns.html",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "",
    "text": "In this post, I will introduce you to 14 important patterns that can help you solve most of the problems on Leetcode. I will provide a template for each pattern to help you quickly apply it to a problem, as well as a list of important problems to practice with. By the end of this post, you will have a powerful set of tools to enhance your problem-solving skills on Leetcode and beyond. Let’s get started!"
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#sliding-window",
    "href": "posts/13-leetcode-patterns.html#sliding-window",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "1. Sliding Window",
    "text": "1. Sliding Window\nThe sliding window pattern is a common technique used to solve problems involving arrays or strings. It involves using a fixed-size “window” that slides through the array or string, and performs some operation on each sub-array or sub-string that it covers. This allows you to perform the operation on each possible sub-array or sub-string without having to create a new array or string for each one.\nHere is a simple template in Python that you can use to solve any problem that uses the sliding window pattern:\nTemplate\n# initialize the window\nwindow_start = 0\nwindow_end = 0\n\n# initialize any other variables you need\nresult = 0\n\n# loop until the window_end reaches the end of the array/string\nwhile window_end &lt; len(arr):\n  # perform the operation on the current sub-array/sub-string\n  result = update_result(arr[window_start:window_end+1], result)\n\n  # move the window to the right\n  window_start += 1\n  window_end += 1\n\n# return the final result\nreturn result\nTo use this template, you just need to define the update_result() function, which should take in the current sub-array/sub-string and the current result, and return an updated result.\nPractise\nHere are some important problems on leetcode that can be solved using the sliding window pattern:\n\nLongest Substring Without Repeating Characters: This problem involves finding the longest substring in a string that does not contain any repeating characters. The sliding window pattern can be used to efficiently search for this substring.\nMinimum Size Subarray Sum: This problem involves finding the smallest subarray in an array that has a given sum. The sliding window pattern can be used to efficiently search for this subarray.\nPermutation in String: This problem involves checking whether one string is a permutation of another string. The sliding window pattern can be used to efficiently compare the two strings and check for a permutation.\nLongest Substring with At Most Two Distinct Characters 💰: This problem involves finding the longest substring in a string that contains at most two distinct characters. The sliding window pattern can be used to efficiently search for this substring.\nMinimum Window Substring: This problem involves finding the smallest substring in a string that contains all of the characters in another string. The sliding window pattern can be used to efficiently search for this substring."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#two-pointers",
    "href": "posts/13-leetcode-patterns.html#two-pointers",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "2. Two pointers",
    "text": "2. Two pointers\nThe two pointers pattern is a common technique used to solve problems involving arrays or strings. It involves using two “pointers” that point to different elements in the array or string, and moving them in a specific way to perform some operation on the sub-array or sub-string they cover. This allows you to perform the operation on each possible sub-array or sub-string without having to create a new array or string for each one.\nHere is a simple template in Python that you can use to solve any problem that uses the two pointers pattern:\nTemplate\n# initialize the pointers\npointer1 = 0\npointer2 = 0\n\n# initialize any other variables you need\nresult = 0\n\n# loop until the pointers reach the end of the array/string\nwhile pointer1 &lt; len(arr) and pointer2 &lt; len(arr):\n  # perform the operation on the current sub-array/sub-string\n  result = update_result(arr[pointer1:pointer2+1], result)\n\n  # move the pointers according to the specific rules of the pattern\n  pointer1, pointer2 = move_pointers(pointer1, pointer2)\n\n# return the final result\nreturn result\nTo use this template, you just need to define the move_pointers() and update_result() functions. The move_pointers() function should take in the current values of the pointers, and return updated values for the pointers according to the specific rules of the pattern. The update_result() function should take in the current sub-array/sub-string and the current result, and return an updated result.\nPractise\nHere are some important problems on leetcode that can be solved using the two pointers pattern:\n\nTwo Sum: This problem involves finding two numbers in an array that add up to a given target number. The two pointers pattern can be used to efficiently search for these numbers by moving the pointers in opposite directions.\nRemove Duplicates from Sorted Array: This problem involves removing duplicate elements from a sorted array. The two pointers pattern can be used to efficiently remove the duplicates by comparing the elements at each pointer and moving them as necessary.\nContainer With Most Water: This problem involves finding the maximum area of a container formed by two lines on a graph. The two pointers pattern can be used to efficiently search for the maximum area by moving the pointers in opposite directions.\nTrapping Rain Water: This problem involves finding the amount of rainwater that can be trapped between bars on a histogram. The two pointers pattern can be used to efficiently calculate the trapped water by moving the pointers inwards from the ends of the array."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#fast-and-slow-pointers",
    "href": "posts/13-leetcode-patterns.html#fast-and-slow-pointers",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "3. Fast and slow pointers",
    "text": "3. Fast and slow pointers\nThe fast and slow pointers pattern is a common technique used to solve problems involving linked lists. It involves using two pointers that traverse the linked list at different speeds. The “slow” pointer moves one step at a time, while the “fast” pointer moves two steps at a time. This allows the fast pointer to “lap” the slow pointer, and makes it possible to detect when the two pointers are pointing to the same node (i.e., they have “collided”).\nTemplate\n# initialize the pointers\nslow_pointer = linked_list.head\nfast_pointer = linked_list.head\n\n# initialize any other variables you need\nresult = 0\n\n# loop until the pointers reach the end of the linked list\nwhile fast_pointer is not None and fast_pointer.next is not None:\n  # perform the operation on the current nodes\n  result = update_result(slow_pointer, fast_pointer, result)\n\n  # move the pointers according to the specific rules of the pattern\n  slow_pointer = slow_pointer.next\n  fast_pointer = fast_pointer.next.next\n\n  # check if the pointers have collided\n  if slow_pointer == fast_pointer:\n    break\n\n# return the final result\nreturn result\nTo use this template, you just need to define the update_result() function, which should take in the current values of the slow and fast pointers, and the current result, and return an updated result.\nPractise\nHere are some important problems on leetcode that can be solved using the fast and slow pointers pattern:\n\nLinked List Cycle: This problem involves detecting whether a linked list contains a cycle. The fast and slow pointers pattern can be used to efficiently detect the cycle by moving the pointers at different speeds and checking for overlap.\nMiddle of the Linked List: This problem involves finding the middle element of a linked list. The fast and slow pointers pattern can be used to efficiently find the middle element by moving the pointers at different speeds and stopping when the fast pointer reaches the end of the list.\nHappy Number: This problem involves determining whether a number is a happy number. The fast and slow pointers pattern can be used to efficiently check for happiness by moving the pointers at different speeds and checking for a cycle. Reorder List: This problem involves reordering the elements of a linked list in a specific way. The fast and slow pointers pattern can be used to efficiently reorder the elements by moving the pointers at different speeds and rearranging the elements as necessary.\nPalindrome Linked List: This problem involves checking whether a linked list is a palindrome. The fast and slow pointers pattern can be used to efficiently check for palindromicity by moving the pointers at different speeds and comparing the elements at each pointer."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#merge-intervals",
    "href": "posts/13-leetcode-patterns.html#merge-intervals",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "4. Merge Intervals",
    "text": "4. Merge Intervals\nThe merge intervals pattern is a common technique used to solve problems involving sets of intervals. It involves sorting the intervals by their start time, and then merging any intervals that overlap. This allows you to take a set of potentially overlapping intervals and convert it into a set of non-overlapping intervals.\nHere is a simple template in Python that you can use to solve any problem that uses the merge intervals pattern:\nTemplate\n\n# sort the intervals by their start time\nintervals = sorted(intervals, key=lambda x: x[0])\n\n# initialize the result list with the first interval\nresult = [intervals[0]]\n\n# loop through the remaining intervals\nfor i in range(1, len(intervals)):\n  # get the last interval in the result list\n  last_interval = result[-1]\n\n  # check if the current interval overlaps with the last interval\n  if intervals[i][0] &lt;= last_interval[1]:\n    # if it does, merge the current interval with the last interval\n    result[-1] = (last_interval[0], max(last_interval[1], intervals[i][1]))\n  else:\n    # if it doesn't, add the current interval to the result list\n    result.append(intervals[i])\n\n# return the final result\nreturn result\nTo use this template, you just need to provide a list of intervals (in the form of tuples of start and end times), and the template will return a list of non-overlapping intervals.\nPractise\nHere are some important problems on leetcode that can be solved using the merge intervals pattern:\n-Merge Intervals: This problem involves merging a list of intervals that may overlap.\n\nInsert Interval: This problem involves inserting a new interval into a list of intervals that may overlap.\nMeeting Rooms: This problem involves checking whether it is possible to attend all of the meetings in a list of intervals.\nMeeting Rooms II: This problem involves finding the minimum number of rooms needed to hold all of the meetings in a list of intervals.\nMinimum Number of Arrows to Burst Balloons: This problem involves finding the minimum number of arrows needed to burst a given set of balloons."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#cyclic-sort",
    "href": "posts/13-leetcode-patterns.html#cyclic-sort",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "5. Cyclic sort",
    "text": "5. Cyclic sort\nCyclic sort is a technique used to sort a list of numbers that are in a certain range, but not necessarily in the correct order. It involves looping through the list and “cycling” the numbers into the correct positions. For example, if the list is [3, 1, 5, 4, 2] and the range is 1 to 5, the first step would be to put the 1 in its correct position at index 0, the second step would be to put the 2 in its correct position at index 1, and so on.\nTemplate\n# initialize the current index and the number of items to sort\ncurrent_index = 0\nnum_to_sort = len(arr)\n\n# loop until all items have been sorted\nwhile num_to_sort &gt; 0:\n  # get the correct value for the current index\n  correct_value = current_index + 1\n\n  # check if the current value is already correct\n  if arr[current_index] == correct_value:\n    # if it is, move on to the next index\n    current_index += 1\n    num_to_sort -= 1\n  else:\n    # if it isn't, swap the current value with the correct value\n    arr[current_index], arr[arr[current_index] - 1] = arr[arr[current_index] - 1], arr[current_index]\n\n# return the sorted array\nreturn arr\nTo use this template, you just need to provide a list of numbers that are in a certain range, and the template will return the sorted list.\nPractise\nHere are some important problems on leetcode that can be solved using the cyclic sort pattern:\n\nFind the Duplicate Number: This problem involves finding the duplicate element in an array of numbers that are in the range 1 to n.\nFind the Missing Number: This problem involves finding the missing element in an array of numbers that are in the range 1 to n.\nFirst Missing Positive: This problem involves finding the smallest missing positive number in an array of numbers.\nFind All Duplicates in an Array: This problem involves finding all of the duplicate elements in an array of numbers."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#in-place-reversal-of-linked-list",
    "href": "posts/13-leetcode-patterns.html#in-place-reversal-of-linked-list",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "6. In-place reversal of linked-list",
    "text": "6. In-place reversal of linked-list\n“In-place reversal of a linked list” refers to a technique for reversing the order of the nodes in a linked list without using any additional data structures. This is done by changing the links between the nodes in the linked list so that the nodes are connected in the opposite order.\nTemplate\n# initialize the previous, current, and next nodes\nprev_node = None\ncurr_node = linked_list.head\nnext_node = None\n\n# loop until the current node is None\nwhile curr_node is not None:\n  # store the next node\n  next_node = curr_node.next\n\n  # reverse the link between the current and previous nodes\n  curr_node.next = prev_node\n\n  # move the previous and current nodes forward\n  prev_node = curr_node\n  curr_node = next_node\n\n# set the head of the linked list to the new start node\nlinked_list.head = prev_node\nTo use this template, you just need to provide a linked list object and the template will reverse the order of the nodes in the linked list.\nPractise\nHere are some important problems on leetcode that can be solved using the in-place reversal of linked list pattern:\n\nReverse Linked List: This problem involves reversing the order of elements in a linked list.\nReverse Linked List II: This problem involves reversing a portion of a linked list.\nPalindrome Linked List: This problem involves checking whether a linked list is a palindrome.\nReorder List: This problem involves reordering the elements of a linked list in a specific way.\nSwap Nodes in Pairs: This problem involves swapping the nodes in a linked list in pairs."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#tree-bfs",
    "href": "posts/13-leetcode-patterns.html#tree-bfs",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "7. Tree BFS",
    "text": "7. Tree BFS\nThe tree BFS (Breadth-First Search) pattern is a technique used to traverse the nodes of a tree in a level-by-level order. In the case of a binary tree (i.e., a tree in which each node has at most two children), the tree BFS algorithm can be implemented as follows:\nTemplate\n# initialize the queue with the root node\nqueue = [root]\n\n# initialize any other variables you need\nresult = []\n\n# loop until the queue is empty\nwhile len(queue) &gt; 0:\n  # get the next node from the queue\n  current_node = queue.pop(0)\n\n  # perform the operation on the current node\n  result = update_result(current_node, result)\n\n  # add the left and right child nodes of the current node to the queue\n  if current_node.left is not None:\n    queue.append(current_node.left)\n  if current_node.right is not None:\n    queue.append(current_node.right)\n\n# return the final result\nreturn result\nTo use this template, you just need to provide the root node of the binary tree and define the update_result() function, which should take in the current node and the current result, and return an updated result.\nPractise\nHere are some important problems on leetcode that can be solved using the tree BFS pattern:\n\nBinary Tree Level Order Traversal: This problem involves performing a level-order traversal of a binary tree.\nMinimum Depth of Binary Tree: This problem involves finding the minimum depth of a binary tree.\nSymmetric Tree: This problem involves checking whether a binary tree is symmetric.\nBinary Tree Zigzag Level Order Traversal: This problem involves performing a zigzag-level-order traversal of a binary tree.\nSerialize and Deserialize Binary Tree: This problem involves serializing and deserializing a binary tree."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#tree-dfs",
    "href": "posts/13-leetcode-patterns.html#tree-dfs",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "8. Tree DFS",
    "text": "8. Tree DFS\nThe tree DFS (Depth-First Search) pattern is a technique used to traverse the nodes of a tree in a depth-first manner. In the case of a binary tree (i.e., a tree in which each node has at most two children), the tree DFS algorithm can be implemented as follows:\nTemplate\n# initialize any other variables you need\nresult = []\n\n# perform the DFS traversal on the root node\ntraverse(root, result)\n\n# return the final result\nreturn result\n\ndef traverse(node, result):\n  # perform the operation on the current node\n  result = update_result(node, result)\n\n  # recursively traverse the left and right child nodes of the current node\n  if node.left is not None:\n    traverse(node.left, result)\n  if node.right is not None:\n    traverse(node.right, result)\nTo use this template, you just need to provide the root node of the binary tree and define the update_result() function, which should take in the current node and the current result, and return an updated result.\nPractise\nHere are some important problems on leetcode that can be solved using the tree DFS pattern:\n\nBinary Tree Preorder Traversal: This problem involves performing a preorder traversal of a binary tree.\nValidate Binary Search Tree: This problem involves checking whether a binary tree is a valid binary search tree.\nMaximum Depth of Binary Tree: This problem involves finding the maximum depth of a binary tree."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#two-heaps",
    "href": "posts/13-leetcode-patterns.html#two-heaps",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "9. Two heaps",
    "text": "9. Two heaps\nThe “two heaps” pattern is a common technique used to solve problems involving sets of numbers. It involves using two heaps (i.e., data structures that provide efficient ways to insert and remove items, and to find the minimum or maximum item) to store the numbers in the set. This allows you to efficiently maintain certain properties of the numbers in the set, and to quickly perform operations on the numbers when needed.\nTemplate\nimport heapq\n\n# initialize the two heaps\nheap1 = []\nheap2 = []\n\n# initialize any other variables you need\n\n# loop through the numbers in the set\nfor num in nums:\n  # insert the number into the appropriate heap\n  if condition1:\n    heapq.heappush(heap1, num)\n  else:\n    heapq.heappush(heap2, num)\n\n  # balance the heaps if necessary\n  if condition2:\n    heapq.heappush(heap2, heapq.heappop(heap1))\n  elif condition3:\n    heapq.heappush(heap1, heapq.heappop(heap2))\n\n  # update any other variables you need\n  update_variables(num)\n\n# return the final result\nreturn result\nTo use this template, you just need to provide a list of numbers and define the condition1, condition2, condition3, and update_variables() functions. These functions should determine which heap to insert the current number into, whether the heaps need to be balanced, and how to update any other variables you need.\nFor example, if you want to use the two heaps pattern to find the median of a set of numbers, you could define the following functions:\n# insert the number into the smaller_half heap if it is smaller than the current median,\n# or into the larger_half heap if it is larger or equal to the current median\ndef condition1(num, median):\n  return num &lt; median\n\n# balance the heaps if the size difference between them is greater than 1\ndef condition2(smaller_half, larger_half):\n  return len(smaller_half) &gt; len(larger_half) + 1\n\n# balance the heaps if the size difference between them is greater than 1\ndef condition3(smaller_half, larger_half):\n  return len(larger_half) &gt; len(smaller_half) + 1\n\n# update the median if the size of the two heaps is equal, or if one heap is larger than the other\ndef update_variables(num, median, smaller_half, larger_half):\n  if len(smaller_half) == len(larger_half):\n    median = (-smaller_half[0] + larger_half[0]) / 2\n  elif len(smaller_half) &gt; len(larger_half):\n    median = -smaller_half[0]\n  else:\n    median = larger_half[0]\nPractise\nHere are some important problems on leetcode that can be solved using the two heaps pattern:\n\nKth Largest Element in an Array: This problem involves finding the kth largest element in an array.\nMedian of Two Sorted Arrays: This problem involves finding the median of two sorted arrays.\nSliding Window Median: This problem involves finding the median of the elements in a sliding window of an array.\nTop K Frequent Elements: This problem involves finding the k most frequent elements in an array.\nKth Smallest Element in a Sorted Matrix: This problem involves finding the kth smallest element in a sorted matrix."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#subsets",
    "href": "posts/13-leetcode-patterns.html#subsets",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "10. Subsets",
    "text": "10. Subsets\nThe “subsets” pattern is a common technique used to solve problems involving sets of numbers. It involves generating all possible subsets of the set and then performing some operation on each subset to find the desired result. This allows you to consider all possible combinations of numbers in the set and to efficiently compute the result for each combination.\nTemplate 1\n# initialize the result\nresult = []\n\n# generate all possible subsets of the set\nfor subset in itertools.combinations(nums, r) for r in range(len(nums)+1):\n  # perform the operation on the current subset\n  result = update_result(subset, result)\n\n# return the final result\nreturn result\nTemplate 2\n# initialize the result\nresult = []\n\n# generate all possible subsets of the set\nfor i in range(1, 2**len(nums)):\n  # convert the binary representation of i to a list of indices\n  indices = [j for j in range(len(nums)) if i & (1 &lt;&lt; j)]\n\n  # generate the current subset\n  subset = [nums[j] for j in indices]\n\n  # perform the operation on the current subset\n  result = update_result(subset, result)\n\n# return the final result\nreturn result\nIt uses a single loop and binary operations to generate the subsets. It converts the binary representation of each number in the range 1..2^len(nums) to a list of indices, and then uses those indices to select the elements of the set that are included in the current subset.\nPractise\nHere are some important problems on leetcode that can be solved using the subsets pattern:\n\nSubsets: This problem involves generating all of the subsets of a given set of elements.\nSubsets II: This problem involves generating all of the subsets of a given set of elements, allowing for duplicates.\nPermutations: This problem involves generating all of the permutations of a given set of elements.\nPermutations II: This problem involves generating all of the permutations of a given set of elements, allowing for duplicates.\nCombination Sum: This problem involves finding all of the combinations of a given set of elements that add up to a specific target sum."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#modified-binary-search",
    "href": "posts/13-leetcode-patterns.html#modified-binary-search",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "11. Modified Binary Search",
    "text": "11. Modified Binary Search\nThe “modified binary search” pattern is a common technique used to solve problems involving a sorted array of numbers. It is similar to regular binary search, but it allows you to modify the condition used to determine whether to search the left or right half of the array. This can be useful if the problem you’re trying to solve involves finding the position of an element in the array that satisfies a certain condition, or if the array has duplicate elements and you need to find the first or last occurrence of a given element.\nTemplate\n# initialize the left and right pointers\nleft = 0\nright = len(nums) - 1\n\n# search the array until the left and right pointers meet\nwhile left &lt; right:\n  # calculate the middle index\n  mid = left + (right - left) // 2\n\n  # modify the condition used to determine which half of the array to search\n  if condition(nums[mid]):\n    right = mid\n  else:\n    left = mid + 1\n\n# return the final result\nreturn left\nIf you want to use the modified binary search pattern to find the first occurrence of a given element in an array, you could define the following condition() function:\ndef condition(num):\n  return num == target and (mid == 0 or nums[mid-1] != target)\nThis function checks whether the current element is equal to the target element and whether it is the first occurrence of that element in the array (i.e., whether the element before it is not equal to the target). If both of these conditions are satisfied, then the function returns True, indicating that the left pointer should be updated to the current index. Otherwise, it returns False, indicating that the right pointer should be updated to the current index.\nPractise\nHere are some important problems on leetcode that can be solved using the modified binary search pattern:\n\nSearch in Rotated Sorted Array: This problem involves searching for an element in a rotated sorted array.\nFind Minimum in Rotated Sorted Array: This problem involves finding the minimum element in a rotated sorted array.\nSearch in Rotated Sorted Array II: This problem involves searching for an element in a rotated sorted array that may contain duplicates.\nFind Peak Element: This problem involves finding a peak element in an array.\nFind K Closest Elements: This problem involves finding the k closest elements to a given target in an array."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#top-k-elements",
    "href": "posts/13-leetcode-patterns.html#top-k-elements",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "12. Top K elements",
    "text": "12. Top K elements\nThe “top k elements” pattern is a common technique used to solve problems involving a large set of numbers. It involves finding the largest or smallest k elements in the set and then performing some operation on those elements to find the desired result. This allows you to efficiently select the most important elements from the set and to compute the result using only those elements.\nTemplate\n# initialize the heap with the first k elements of the set\nheap = nums[:k]\n\n# heapify the heap\nheapq.heapify(heap)\n\n# loop through the remaining elements of the set\nfor num in nums[k:]:\n  # insert the current element into the heap if it is larger than the smallest element in the heap\n  if num &gt; heap[0]:\n    heapq.heappushpop(heap, num)\n\n# return the final result\nreturn operation(heap)\nFor example, if you want to use the top k elements pattern to find the sum of the largest k elements in a set, you could define the following operation() function:\ndef operation(heap):\n  return sum(heap)\nThis function simply returns the sum of all the elements in the heap, which are the largest k elements in the set\nPractise\nHere are some important problems on leetcode that can be solved using the top k elements pattern:\n\nKth Largest Element in an Array: This problem involves finding the kth largest element in an array.\nTop K Frequent Elements: This problem involves finding the k most frequent elements in an array.\nKth Smallest Element in a Sorted Matrix: This problem involves finding the kth smallest element in a sorted matrix.\nSort Colors: This problem involves sorting an array of colors (represented as numbers) in place.\nMinimum Cost to Hire K Workers: This problem involves finding the minimum cost to hire k workers, given their wage and productivity."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#k-way-merge-using-heap",
    "href": "posts/13-leetcode-patterns.html#k-way-merge-using-heap",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "13. K-way Merge (using heap)",
    "text": "13. K-way Merge (using heap)\nThe k-way merge pattern using a heap is a common technique used to merge k sorted arrays into a single sorted array. It involves using a heap data structure to efficiently select the smallest element from the k arrays and to add it to the result. This allows you to efficiently combine the k arrays into a single sorted array and to perform further operations on that array.\nTemplate\n# initialize the result and the heap with the first elements of the k arrays\nresult = []\nheap = [(arrays[i][0], i) for i in range(k)]\n\n# heapify the heap\nheapq.heapify(heap)\n\n# loop until all the arrays have been merged\nwhile heap:\n  # get the smallest element from the heap\n  min_element, min_index = heapq.heappop(heap)\n\n  # add the smallest element to the result\n  result.append(min_element)\n\n  # insert the next element from the array where the smallest element was found into the heap\n  if min_index &lt; len(arrays[min_index]) - 1:\n    heapq.heappush(heap, (arrays[min_index][min_index+1], min_index))\n\n# return the final result\nreturn result\nPractise\nHere are some important problems on leetcode that can be solved using the k-way merge (using heap) pattern:\n\nMerge k Sorted Lists: This problem involves merging k sorted linked lists into a single sorted linked list.\nThe Skyline Problem: This problem involves finding the skyline of a set of buildings.\nMinimum Cost to Connect Sticks: This problem involves connecting a set of sticks with minimum total cost.\nMaximum Number of Events That Can Be Attended: This problem involves finding the maximum number of events that a person can attend, given a list of events with start and end times."
  },
  {
    "objectID": "posts/13-leetcode-patterns.html#topological-sort",
    "href": "posts/13-leetcode-patterns.html#topological-sort",
    "title": "Mastering Common Patterns to Solve Leetcode Problems",
    "section": "14. Topological Sort",
    "text": "14. Topological Sort\nTopological sort is an algorithm that is used to arrange the vertices of a directed acyclic graph (DAG) in a linear order such that, for every directed edge uv from vertex u to vertex v, u comes before v in the ordering. This is useful for problems where a certain set of dependencies must be satisfied, such as scheduling tasks or determining the order in which to assemble a product.\nTo perform a topological sort, we first identify all of the vertices with no incoming edges (i.e., no dependencies) and put them in a queue. We then remove these vertices from the graph and repeat the process until the queue is empty. At each step, we add the vertices we remove to a list, which will eventually give us the topological ordering of the vertices.\nTopological sort is commonly used to solve problems on LeetCode, such as “Course Schedule” and “Alien Dictionary”. It can also be useful for solving other problems that involve dependencies between objects or tasks.\nTemplate\nfrom collections import deque\n\ndef topological_sort(vertices, edges):\n    # Create a list to store the topological ordering of the vertices\n    top_order = []\n\n    # Create a queue to keep track of the vertices with no incoming edges\n    queue = deque()\n\n    # Create a dictionary to store the indegrees of each vertex\n    indegrees = {vertex: 0 for vertex in vertices}\n\n    # Create a dictionary to store the adjacency list for each vertex\n    adj_list = {vertex: [] for vertex in vertices}\n\n    # Populate the indegrees dictionary and adjacency list\n    for edge in edges:\n        u, v = edge\n        indegrees[v] += 1\n        adj_list[u].append(v)\n\n    # Add all vertices with no incoming edges to the queue\n    for vertex, indegree in indegrees.items():\n        if indegree == 0:\n            queue.append(vertex)\n\n    # Perform the topological sort\n    while queue:\n        # Remove a vertex from the queue\n        vertex = queue.popleft()\n\n        # Add the vertex to the topological ordering\n        top_order.append(vertex)\n\n        # Decrement the indegree of each of its neighbors\n        for neighbor in adj_list[vertex]:\n            indegrees[neighbor] -= 1\n\n            # If the indegree of a neighbor becomes 0, add it to the queue\n            if indegrees[neighbor] == 0:\n                queue.append(neighbor)\n\n    # If there are any vertices left in the graph, then the original graph was not a DAG\n    if len(top_order) != len(vertices):\n        return []\n\n    return top_order\nPractise\nHere are some important problems on leetcode that can be solved using the topological sort pattern:\n\nCourse Schedule: This problem involves checking whether a given set of courses can be completed, given the dependencies between the courses.\nCourse Schedule II: This problem involves finding the order in which the courses should be taken in order to complete them all.\nAlien Dictionary: This problem involves reconstructing the order of the letters in an alien language, given a list of words.\nSequence Reconstruction: This problem involves checking whether a given sequence can be reconstructed from a given set of subsequences.\nMinimum Height Trees: This problem involves finding the root(s) of a tree with minimum height."
  },
  {
    "objectID": "posts/3-secret-of-success-by-mark-twain.html",
    "href": "posts/3-secret-of-success-by-mark-twain.html",
    "title": "Secret of Success by Mark Twain",
    "section": "",
    "text": "In today’s world, it can often feel like there are so many things to do and so little time to do them. It can be overwhelming to think about all the tasks and responsibilities that we have, and it can be difficult to know where to even begin. But as the famous author Marc Twain once said,\n\nThe secret of getting ahead is getting started. The secret of getting started is breaking your complex overwhelming tasks into small manageable tasks, and starting on the first one.\n\nIn other words, the key to success is simply to take that first step. It can be intimidating to tackle a large and complex task, but by breaking it down into smaller, manageable pieces, it becomes much more manageable. And once you’ve taken that first step, the rest will start to fall into place.\nThis quote is a great reminder that we don’t have to be perfect from the start. It’s okay to start small and work our way up – in fact, it’s the best way to make progress. So the next time you’re feeling overwhelmed by a big project or task, remember Marc Twain’s words and just start on the first step. You’ll be amazed at how much you can accomplish when you simply get started."
  },
  {
    "objectID": "posts/5-a-simplified-implementation-of-quicksort.html",
    "href": "posts/5-a-simplified-implementation-of-quicksort.html",
    "title": "A Simplified Implementation of Quicksort",
    "section": "",
    "text": "Quicksort is a beautiful algorithm. It’s considered the fastest sorting algorithm in practice. Most implementations I’ve seen online are complicated. This post will demonstrate a simple implementation that trades space complexity for readability."
  },
  {
    "objectID": "posts/5-a-simplified-implementation-of-quicksort.html#how-does-quicksort-work",
    "href": "posts/5-a-simplified-implementation-of-quicksort.html#how-does-quicksort-work",
    "title": "A Simplified Implementation of Quicksort",
    "section": "How does quicksort work?",
    "text": "How does quicksort work?\n3 steps.\n\nChoose a pivot element.\nPartition: Put all elements smaller than the pivot in a smaller array, (say, smaller_subarray). Put all elements greater than the pivot in another array (say, greater_subarray).\nRecurse & Merge: Recursively sort the smaller and greater sub-arrays. Merge the sorted arrays with the pivot."
  },
  {
    "objectID": "posts/5-a-simplified-implementation-of-quicksort.html#how-do-we-implement-it-in-python",
    "href": "posts/5-a-simplified-implementation-of-quicksort.html#how-do-we-implement-it-in-python",
    "title": "A Simplified Implementation of Quicksort",
    "section": "How do we implement it in Python?",
    "text": "How do we implement it in Python?\nLet’s start with the high-level function quicksort()\n\ndef quicksort(array: List[int]) -&gt; List[int]:\n    \"\"\"Recursive implementation of quicksort.\n\n    Args:\n        array (List[int]): a list of integers\n\n    Returns:\n        List[int]: sorted array\n    \"\"\"\n\n    # Base case\n    if len(array) &lt;= 1:\n        return array\n\n    # Step 1: choose a pivot\n    pivot_idx = random.choice(range(len(array)))\n\n    # Step 2: partition\n    smaller_subarray, greater_subarray = partition(array, pivot_idx)\n\n    # Step 3: Recurse on smaller and greater subarrays.\n    return (\n        quicksort(smaller_subarray)\n        + [array[pivot_idx]]\n        + quicksort(greater_subarray)\n    )\nLet’s go line by line,\n\nBase case\n if len(array) &lt;= 1:\n     return array\nEvery recursive function must have one. If we have an empty or single-item array, there’s nothing to sort. We simply return the array.\n\n\nStep 1: Choose a pivot\npivot_idx = random.choice(range(len(array)))\nThe choice of pivot is the difference between having an O(N log N) vs O(N^2) time complexity.\nHow so? Let’s take an example.\nThe worst-case involves having an already sorted array.\narray = [1,2,3,4,5]\nThe image below shows recursion trees using two different pivot selection strategies:\nLegend\n\nBlue lines =&gt; the greater subarray.\nOrange lines =&gt; the smaller subarray.\nRed lines =&gt; the pivot.\n\n\n\n\nScreenshot 2021-09-05 at 1.45.23 PM.png\n\n\n\nLeft shows the case where we always choose the first/last item as the pivot. This leads to higher recursion depth as the subproblem size reduces by 1 at each level. We have roughly O(N) levels / recursive calls. Since joining the sub-arrays with the pivot is O(N), this leads to O(N^2) time complexity.\nRight shows the ideal case where we choose the median as the pivot at every level. This leads to balanced sub-problems. The recursion depth is lower, roughly O(log N). This leads to O(N log N) time complexity.\n\nChoosing a random pivot leads to an expected runtime of O(N log N) time complexity. We use that in this implementation.\nWait! There’s still one case where quicksort() could be O(N^2), even after choosing a randomized/median pivot. This is the case when every item in the array is identical. We could add a check to avoid this case as well.\nAccording to this source ,\n\nThe probability that quicksort will use a quadratic number of compares when sorting a large array on your computer is much less than the probability that your computer will be struck by lightning!\n\n\n\nStep 2: Partition\nWe write the high-level function assuming that we have a magic function partition() which returns two arrays.\n\nsmaller_subarray: all elements &lt;= the pivot\ngreater_subarray: all elements &gt; the pivot\n\nThe implementation of partition() is quite simple. We compare each item in the array with the pivot. If it’s &lt;= pivot, we add it to the smaller sub-array, else we add it to the greater sub-array.\ndef partition(array: List[int], pivot_idx: int) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Parition array into subarrays smaller and greater than the pivot.\n\n    Args:\n        array (List[int]): input array\n        pivot_idx (int): index of the pivot\n\n    Returns:\n        Tuple[List[int], List[int]]: smaller subarray, greater subarray\n    \"\"\"\n    smaller_subarray, greater_subarray = [], []\n    for idx, item in enumerate(array):\n        # we don't want to add pivot to any of the sub-arrays\n        if idx == pivot_idx:\n            continue\n        if item &lt;= array[pivot_idx]:\n            smaller_subarray.append(item)\n        else:\n            greater_subarray.append(item)\n    return smaller_subarray, greater_subarray\n\n\nStep 3: Merge\nreturn (\n        quicksort(smaller_subarray)\n        + [array[pivot_idx]]\n        + quicksort(greater_subarray)\n    )\nThis step is quite exquisite. We recurse on the smaller and greater sub-arrays and place the pivot in between them. The beauty of a recursive implementation is that we could re-use our function with a smaller size of the input and trust that it would work.\nLet’s unroll it a bit.\n\nquicksort(smaller_subarray) =&gt; returns a sorted version of the smaller_subarray\n[array[pivot_idx]] =&gt; out pivot in a list. It’s needed for concatenating it with the other two lists.\nquicksort(greater_subarray) =&gt; returns a sorted version of the greater_subarray\n\nNow, we join the 3 lists including the pivot, and return the final sorted list."
  },
  {
    "objectID": "posts/5-a-simplified-implementation-of-quicksort.html#complexity",
    "href": "posts/5-a-simplified-implementation-of-quicksort.html#complexity",
    "title": "A Simplified Implementation of Quicksort",
    "section": "Complexity",
    "text": "Complexity\n\nTime\nExpected run-time of O(N log N) since it’s a randomized implementation.\nWe do O(N) work at each quicksort() call. The major components are partition() and merge step - both are O(N).\nFor randomized implementation, we have O(log N) levels/recursive calls.\nSo, expected time complexity ~ Number of recursive calls * work done per recursive call ~ O(N) * O(log N) ~ O(N log N)\n\n\nSpace\nO(N) since we use extra space for storing the smaller and greater sub-arrays. The recursion stack also uses O(log N) space. Overall, this implementation uses O(N) space.\nThe in-place implementation without using auxiliary lists would lead to an O(log N) space complexity."
  },
  {
    "objectID": "posts/5-a-simplified-implementation-of-quicksort.html#the-code",
    "href": "posts/5-a-simplified-implementation-of-quicksort.html#the-code",
    "title": "A Simplified Implementation of Quicksort",
    "section": "The code",
    "text": "The code\nThe implementation including the partition() and tests are here."
  },
  {
    "objectID": "posts/16-never-too-late.html",
    "href": "posts/16-never-too-late.html",
    "title": "Never Too Late: The Inspiring Story of Van Gogh",
    "section": "",
    "text": "Have you ever felt like it’s too late to pursue your dreams? Perhaps you feel like you’re too old, or you’ve missed your chance. If so, it’s time to reconsider. The story of Van Gogh is a perfect example of how it’s never too late to start something and become world-class at it.\nVan Gogh is one of the most famous and celebrated artists in history, known for his beautiful and unique paintings. But did you know that he didn’t start painting seriously until he was 27 years old? That’s right, it was well into his adult life before Van Gogh began pursuing his passion for art.\nDespite starting later in life, Van Gogh was incredibly productive. Over the course of just 10 years, he created over 2,000 artworks. And most of those were created in the last two years of his life. In just a short amount of time, Van Gogh was able to achieve incredible success and make a lasting impact on the world of art.\nThis is proof that it’s never too late to start something and become world-class at it. If Van Gogh could do it, so can you. So don’t let age or any other perceived limitations hold you back. It’s never too late to pursue your dreams and make them a reality. Take inspiration from Van Gogh and start working towards your goals today. You never know what you might be capable of achieving."
  },
  {
    "objectID": "posts/9-deep-nn-for-youtube-recommendations.html",
    "href": "posts/9-deep-nn-for-youtube-recommendations.html",
    "title": "Deep Neural Networks for YouTube Recommendations",
    "section": "",
    "text": "Screenshot 2021-08-25 at 12.11.06 AM.png\nYouTube has 100m+ daily active users who consume more than a billion hours’ worth of content every day. 100s of hours of videos are uploaded every second. At that scale, recommending personalized videos is a colossal task.\nI’ve always wondered how YouTube is always able to come up with relevant recommendations that kept me hooked! I found a very interesting paper on Deep Neural networks for YouTube Recommendations. In this post, I will summarise the key ideas."
  },
  {
    "objectID": "posts/9-deep-nn-for-youtube-recommendations.html#the-problem",
    "href": "posts/9-deep-nn-for-youtube-recommendations.html#the-problem",
    "title": "Deep Neural Networks for YouTube Recommendations",
    "section": "The Problem",
    "text": "The Problem\nTo able to come up with relevant & personalized recommendations for every user is a problem because of:\n\nscale: billions of users, billions of videos.\nfreshness: massive volume of videos are uploaded every day. It’s an explore-exploit trade-off between popular vs new content.\nnoise: only sparse implicit user feedback is available for modeling.\n\nIn this paper, the authors demonstrate the usage of deep learning techniques for improving recommendations as opposed to matrix-factorization techniques used earlier."
  },
  {
    "objectID": "posts/9-deep-nn-for-youtube-recommendations.html#key-ideas",
    "href": "posts/9-deep-nn-for-youtube-recommendations.html#key-ideas",
    "title": "Deep Neural Networks for YouTube Recommendations",
    "section": "Key Ideas",
    "text": "Key Ideas\n\nThe problem of recommendations at scale is divided into 2 subproblems:\n\nCandidate Generation - selects a small subset from the overall corpus which might be relevant to the user.\nRanking - ranks the candidate videos based on their relative importance.\n\nFor Candidate Generation, the objective is to predict the next video watch. User search/watch history, demographics, etc are used by a simple feed-forward network as embeddings which are jointly learned during the training.\nFor Ranking, the objective is to model an expected watch time. A score is assigned based on the expected watch time and videos are sorted accordingly.\nSimilar neural network architecture is used for both procedures.\nOffline metrics like precision, recall, ranking loss, etc. are used during development. A/B test is used to determine the final effectiveness of the model. We’ve already explored the discrepancies between offline vs online evaluation in a different post."
  },
  {
    "objectID": "posts/9-deep-nn-for-youtube-recommendations.html#model-architecture",
    "href": "posts/9-deep-nn-for-youtube-recommendations.html#model-architecture",
    "title": "Deep Neural Networks for YouTube Recommendations",
    "section": "Model Architecture",
    "text": "Model Architecture\n\nCandidate generation\n\n\n\nScreenshot 2021-08-29 at 1.31.51 PM.png\n\n\n\n** Problem Formulation:** Recommendation is formulated as an extreme multi-class classification P(w_t = i | U,C) = softmax(v_i . u) where, w_t = video v_i watched at time t U = user C = context v_i = dense video embeddings u = dense user embeddings\n\nThe task of the deep neural network is to learn the embeddings u as a function of user history and context.\nuser completing a video watch is a positive example.\ncandidate sampling & importance weighting is used to sample negative examples.\n\nEmbeddings describing the watch history, user query, demographics, etc are fed to a simple feed-forward neural network having a final softmax layer to learn the class probabilities.\n\nwatch history: dense vector representation of watched video is learned from a sequence of video-ids (just like word2vec).\nuser query: n-gram representations\ndemographics: geographic region, device, age, etc. are used as numerical/categorical features\n\nThe embeddings are jointly learned while training the model via gradient descent back-propagation.\nAge of the video is used to model the time-dependent nature of popular videos. Otherwise, the good old popular videos are going to be selected most of the times, isn’t it?\nWhat’s interesting is that a lot of features were “engineered” as opposed to the promise of deep learning to reduce it.\nTraining data & label:\n\nThere’s an inherent sequence of video consumption. Hence, using random held-out data will be cheating since future information will leak into the training process. The model will overfit! Think about time-series forecasting. A random train-test split won’t work since the future data is not available in production during serving time. \nThe authors propose a model of predicting user’s next watch instead of a randomly held-out watch. This makes sense, as we consume videos in a sequence. For example, if you’re watching a series with several episodes, recommending a random episode from that series doesn’t make sense. \n\nServing:\n\nTo score millions of videos in latency of tens of milliseconds, a nearest neighbor-based search algorithm is used. Exact probability values of softmax() are not required. Hence, a dot product of user and video embeddings could be used to figure out the propensity score of a user u for a particular video v_i. A nearest neighbor search algorithm could be used to figure out the top K candidate videos based on the score.\n\n\n\n\nRanking\n\n\n\nScreenshot 2021-08-29 at 2.56.54 PM.png\n\n\n\nCandidate generation selects a few hundred out of millions of videos. The ranking procedure could make use of more video features as well as user’s interactions with it in order to figure out an order of recommendation.\nThe model architecture is similar to the candidate generation procedure. We assign a score to the videos using weighted logistic regression.\nThe objective to optimize is a function of expected watch time per impression.\nWhy not click-through rate? Well, that would promote clickbait videos instead of quality content. Watch time is a better signal that captures engagement.\nModeling Expected Watch Time\n\nObjective: Predict expected watch time for a given video.\nModel: Weighted Logistic Regression, since the class distributions are imbalanced.\n\nPositive example: the video was watched.\nNegative example: the video was not clicked.\n\nWhat are the weights in “weighted” logistic regression? \n\nPositive examples are weighted by the watch time.\nNegative examples are given a weight of 1.\n\nLoss: cross-entropy"
  },
  {
    "objectID": "posts/9-deep-nn-for-youtube-recommendations.html#references",
    "href": "posts/9-deep-nn-for-youtube-recommendations.html#references",
    "title": "Deep Neural Networks for YouTube Recommendations",
    "section": "References",
    "text": "References\n\nDeep Neural Networks for YouTube Recommendations\nSoftmax"
  },
  {
    "objectID": "posts/4-walk.html",
    "href": "posts/4-walk.html",
    "title": "Walking helps you solve difficult bugs",
    "section": "",
    "text": "If you’re a programmer, you know how frustrating it can be to come across a difficult bug. These pesky little issues can derail your entire day, leaving you feeling frustrated and stuck. But did you know that going for a walk can actually help you solve these difficult bugs?\nIt’s true – walking helps you think better. When you’re stuck on a problem, your mind tends to get stuck in a rut, going over the same information again and again. But when you take a walk, you give your mind a chance to wander and think about the problem in a new way.\nResearch has shown that walking can help to boost creativity and problem-solving skills. One study even found that people who walked while brainstorming came up with more creative ideas than those who sat down. So the next time you’re stuck on a difficult bug, go for a walk and see if it helps.\nBut why does walking help you think better? It’s all thanks to the way that our brains work. When we’re walking, our brains go into a state of “transient hypofrontality,” which means that the prefrontal cortex – the part of the brain responsible for logical thinking and decision-making – becomes less active. This allows our minds to wander and come up with new ideas and solutions.\nSo the next time you’re struggling with a difficult bug, don’t just sit there and stare at your screen. Get up and go for a walk. Not only will it help you clear your mind, but it can also help you come up with new and creative solutions to even the most difficult problems. Happy coding!"
  },
  {
    "objectID": "posts/10-fbeta.html",
    "href": "posts/10-fbeta.html",
    "title": "Beyond F1: using the Fbeta_score for better model evaluation",
    "section": "",
    "text": "Hey everyone!\nToday I want to talk about a little-known evaluation metric: Fbeta_score.\nIf you’re familiar with machine learning, you’ve probably heard of F1 score. It’s a common metric used to evaluate the performance of classification models, and it’s defined as the harmonic mean of precision and recall. This is great for a lot of tasks, but there are some situations where F1 score might not be the best choice.\nEnter Fbeta_score. It’s similar to F1 score, but it allows you to adjust the balance between precision and recall by changing the value of beta. This can be useful in situations where you want to emphasize one of these metrics over the other.\nFor example, let’s say you’re training a model to predict whether an image contains a cat or a dog. If you’re using F1 score, you’re treating precision and recall equally, but what if you want to put more emphasis on recall? This is where Fbeta_score comes in handy. By setting beta to a value greater than 1, you can increase the weight of recall in the metric, and by setting it to a value less than 1, you can decrease the weight of recall.\nFbeta_score = (1 + beta^2) * (precision * recall) / (beta^2 * precision + recall)\nwhere precision is the fraction of true positives over the sum of true positives and false positives, and recall is the fraction of true positives over the sum of true positives and false negatives.\nHow to choose a beta?\nbeta = 1 When beta=1, the Fbeta_score is equivalent to the F1 score, which treats precision and recall equally. This is a good default value to use if you don’t have any specific preferences or requirements regarding the balance between precision and recall.\nbeta &lt; 1 If you want to emphasize precision over recall, you can use a value of beta less than 1. For example, setting beta=0.5 will give precision twice as much weight as recall in the metric. This can be useful if you want to minimize the number of false positives, or if the cost of a false positive is higher than the cost of a false negative.\nbeta &gt; 1 On the other hand, if you want to emphasize recall over precision, you can use a value of beta greater than 1. For example, setting beta=2 will give recall twice as much weight as precision in the metric. This can be useful if you want to maximize the number of true positives, or if the cost of a false negative is higher than the cost of a false positive.\nIn general, the best value of beta to use will depend on the specific goals and requirements of the task at hand. By experimenting with different values of beta, you can find the setting that produces the best results for your specific dataset and task.\nHere’s how to use Fbeta_score in Python:\nfrom sklearn.metrics import fbeta_score\n\n# Generate some predictions\ny_pred = [1, 0, 1, 1, 0, 0]\n\n# Compute the Fbeta_score\nfbeta_score(y_true, y_pred, beta=1.0)\nIn the code above, y_pred is a list of binary predictions, and y_true is a list of ground-truth labels. We can then use the fbeta_score function from scikit-learn to compute the Fbeta_score. By default, this will compute the F1 score (i.e. beta=1.0), but you can adjust the value of beta to change the balance between precision and recall."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Saikat Kumar Dey",
    "section": "",
    "text": "Why are mobilenets so fast?\n\n\n\n\n\nLet’s try to understand what differentiates mobilenets from standard CNN architectures\n\n\n\n\n\n\nNov 26, 2023\n\n\n\n\n\n\n\n\nSnapSort - Sorting your photos locally using OpenAI’s CLIP model\n\n\n\n\n\nSnapSort is a CLI tool that uses OpenAI’s CLIP model to sort your photos locally.\n\n\n\n\n\n\nNov 14, 2023\n\n\n\n\n\n\n\n\nHow to Run Large Language Models on Your Laptop with Ollama.ai\n\n\n\n\n\nYou can easily run LLMs on your laptop with Ollama.ai. This post shows you how.\n\n\n\n\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\nMinimalist iOS Habit Tracking App\n\n\n\n\n\nI built a simple, offline habit tracking app for myself using SwiftUI to learn practical iOS development skills and end up with a custom productivity tool tailored to my needs.\n\n\n\n\n\n\nJul 11, 2023\n\n\n\n\n\n\n\n\nHow to Live on 24 Hours a Day by Arnold Bennett\n\n\n\n\n\nA short review\n\n\n\n\n\n\nMay 21, 2023\n\n\n\n\n\n\n\n\nI summarised a 3 hour long youtube video using Langchain + Claude\n\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2023\n\n\n\n\n\n\n\n\nBeyond F1: using the Fbeta_score for better model evaluation\n\n\n\n\n\nLearn how to use the Fbeta_score, a powerful and flexible evaluation metric for classification tasks that allows the user to adjust the balance between precision and recall.\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\nSolving Class Imbalance with Focal Loss\n\n\n\n\n\nFocal loss is an effective technique for addressing class imbalance in machine learning by weighting the loss function to focus on hard-to-classify examples.\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\nHow to love what you do\n\n\n\n\n\nThoughts on creating passion for your work\n\n\n\n\n\n\nJul 2, 2022\n\n\n\n\n\n\n\n\nMastering Common Patterns to Solve Leetcode Problems\n\n\n\n\n\nKnowing these patterns can help you solve most of the problems in leetcode.\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n\n\nWalking helps you solve difficult bugs\n\n\n\n\n\nWalking helps you think better\n\n\n\n\n\n\nJun 15, 2022\n\n\n\n\n\n\n\n\nAccuracy Is a Poor evaluation Metric\n\n\n\n\n\nIssues with using accuracy as an evaluation metric and what you should use instead\n\n\n\n\n\n\nJun 7, 2022\n\n\n\n\n\n\n\n\nSecret of Success by Mark Twain\n\n\n\n\n\nTimeless wisdom\n\n\n\n\n\n\nJun 4, 2022\n\n\n\n\n\n\n\n\nThe Importance of Focusing on One Thing at a Time\n\n\n\n\n\nTake a step back and breathe\n\n\n\n\n\n\nMay 30, 2022\n\n\n\n\n\n\n\n\nNever Too Late: The Inspiring Story of Van Gogh\n\n\n\n\n\nIt’s never too late to start pursuing your dreams\n\n\n\n\n\n\nMay 29, 2022\n\n\n\n\n\n\n\n\nThe Power of Consistent Investing\n\n\n\n\n\nNote to self on investment.\n\n\n\n\n\n\nMay 28, 2022\n\n\n\n\n\n\n\n\nBuilding Pandas Dataframes From Ndarrays\n\n\n\n\n\nHow to convert multi-dimensional numpy arrays to pandas dataframe?\n\n\n\n\n\n\nSep 28, 2021\n\n\n\n\n\n\n\n\nA Simplified Implementation of Quicksort\n\n\n\n\n\nA simple implementation of quicksort that trades space complexity for readability\n\n\n\n\n\n\nSep 5, 2021\n\n\n\n\n\n\n\n\nDeep Neural Networks for YouTube Recommendations\n\n\n\n\n\nPaper summary on how to generate relevant YouTube recommendations\n\n\n\n\n\n\nAug 29, 2021\n\n\n\n\n\n\nNo matching items"
  }
]